{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CS441 – Graph Isomorphism Project\n",
        "This notebook implements the four algorithms required in the project:\n",
        "1. Brute-force isomorphism search  \n",
        "2. Backtracking  \n",
        "3. Degree-based backtracking  \n",
        "4. Weisfeiler–Leman backtracking  \n",
        "\n",
        "Each function strictly follows the specifications and returns:\n",
        "- `(True, mapping)` if the graphs are isomorphic  \n",
        "- `(False, [])` otherwise\n",
        "\n",
        "Graphs are loaded from text files according to the required format.\n"
      ],
      "metadata": {
        "id": "wJAUp53fVNwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1 — Imports\n",
        "This section loads all required Python packages.\n",
        "\n",
        "The project does not allow external libraries, so we only use:\n",
        "- itertools (for permutations)\n",
        "- typing (for type clarity)\n",
        "- copy (for safe duplication of partitions/mappings)\n"
      ],
      "metadata": {
        "id": "Lwp92daxVNdr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F598YV_XUBRe"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# Section 1 - Imports\n",
        "# ============================================\n",
        "\n",
        "from itertools import permutations\n",
        "from typing import List, Set, Dict, Tuple, Union\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2 — Graph Loading and Basic Utilities\n",
        "\n",
        "This section contains helper functions used throughout the algorithms:\n",
        "\n",
        "### `load_graph(path)`\n",
        "Reads a graph from a text file and returns its adjacency structure.\n",
        "\n",
        "### `check_isomorphism_from_mapping`\n",
        "Given a bijection ρ between nodes of `G1` and `G2`, checks whether all edges\n",
        "are preserved.\n",
        "\n",
        "### `quick_invariants_match`\n",
        "Performs fast necessary checks before running expensive algorithms:\n",
        "- same number of nodes\n",
        "- same degree multiset\n",
        "\n",
        "### `_build_degree_partition`\n",
        "Creates the initial partition of nodes based on degrees (Question 3).\n"
      ],
      "metadata": {
        "id": "410x6975ULX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Section 2 - Graph loading and basic helpers\n",
        "# ============================================\n",
        "\n",
        "from typing import List, Set, Dict, Tuple, Union\n",
        "\n",
        "def load_graph(path: str) -> List[Set[int]]:\n",
        "    \"\"\"\n",
        "    Load an undirected graph from a text file with the format:\n",
        "\n",
        "      Line 1:  n  m\n",
        "          n = number of nodes (0..n-1)\n",
        "          m = number of edges (not strictly needed here)\n",
        "      Line 2: neighbors of node 0 (space-separated)\n",
        "      Line 3: neighbors of node 1\n",
        "      ...\n",
        "      Line n+1: neighbors of node n-1\n",
        "\n",
        "    Returns:\n",
        "      adj: list of length n where adj[i] is a set of neighbors of node i.\n",
        "    \"\"\"\n",
        "    with open(path, \"r\") as f:\n",
        "        first_line = f.readline().split()\n",
        "        if not first_line:\n",
        "            raise ValueError(\"Empty file or invalid format\")\n",
        "\n",
        "        n = int(first_line[0])\n",
        "        # m = int(first_line[1])  # not needed for the algorithms\n",
        "\n",
        "        adj = [set() for _ in range(n)]\n",
        "        for i in range(n):\n",
        "            line = f.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            neighbors = line.split()\n",
        "            for nb in neighbors:\n",
        "                v = int(nb)\n",
        "                adj[i].add(v)\n",
        "                # Input is assumed symmetric (undirected).\n",
        "                # If it was not, we could force symmetry with: adj[v].add(i)\n",
        "    return adj\n",
        "\n",
        "\n",
        "def check_isomorphism_from_mapping(\n",
        "    adj1: List[Set[int]],\n",
        "    adj2: List[Set[int]],\n",
        "     mapping: List[int]\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Check if 'mapping' is an isomorphism between adj1 and adj2.\n",
        "\n",
        "    Condition:\n",
        "      (i, j) in E1  <=>  (mapping[i], mapping[j]) in E2\n",
        "    for all 0 <= i < j < n.\n",
        "    \"\"\"\n",
        "    n = len(adj1)\n",
        "    for i in range(n):\n",
        "        mi = mapping[i]\n",
        "        for j in range(i + 1, n):\n",
        "            mj = mapping[j]\n",
        "            edge1 = j in adj1[i]\n",
        "            edge2 = mj in adj2[mi]\n",
        "            if edge1 != edge2:\n",
        "                return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def quick_invariants_match(adj1: List[Set[int]], adj2: List[Set[int]]) -> bool:\n",
        "    \"\"\"\n",
        "    Quick necessary checks before running expensive algorithms:\n",
        "\n",
        "    - Same number of nodes.\n",
        "    - Same multiset of degrees.\n",
        "    \"\"\"\n",
        "    if len(adj1) != len(adj2):\n",
        "        return False\n",
        "\n",
        "    deg1 = sorted(len(adj1[i]) for i in range(len(adj1)))\n",
        "    deg2 = sorted(len(adj2[i]) for i in range(len(adj2)))\n",
        "    return deg1 == deg2\n",
        "\n",
        "\n",
        "def _build_degree_partition(adj: List[Set[int]]) -> Tuple[List[int], List[List[int]]]:\n",
        "    \"\"\"\n",
        "    Build the degree partition of a graph.\n",
        "\n",
        "    IMPORTANT (project requirement):\n",
        "    - The part index j IS the degree.\n",
        "    - P(j) contains exactly the nodes with degree j.\n",
        "\n",
        "    Returns:\n",
        "      node_to_part: list of size n, node_to_part[v] = degree(v)\n",
        "      parts      : list of lists, parts[d] = [nodes of degree d]\n",
        "                    (some parts may be empty if no node has that degree)\n",
        "    \"\"\"\n",
        "    n = len(adj)\n",
        "    degrees = [len(adj[v]) for v in range(n)]\n",
        "    if n == 0:\n",
        "        return [], []\n",
        "\n",
        "    max_deg = max(degrees)\n",
        "\n",
        "    # parts[d] will contain all nodes of degree d\n",
        "    parts: List[List[int]] = [[] for _ in range(max_deg + 1)]\n",
        "    node_to_part = [-1] * n\n",
        "\n",
        "    for v in range(n):\n",
        "        d = degrees[v]\n",
        "        parts[d].append(v)\n",
        "        node_to_part[v] = d\n",
        "\n",
        "    return node_to_part, parts\n"
      ],
      "metadata": {
        "id": "9x0DvNDJZz4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3 — Question 1: Brute Force Algorithm\n",
        "\n",
        "This algorithm generates **all permutations** of nodes of the second graph\n",
        "and checks which one preserves adjacency.\n",
        "\n",
        "Although extremely slow for large graphs (because it tries `n!` mappings),\n",
        "it is required as part of the project.\n",
        "\n",
        "### Function provided:\n",
        "- `brute_force(path1, path2)`\n"
      ],
      "metadata": {
        "id": "znm5ruPXUMz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Section 3 - Question 1: Brute force\n",
        "# ============================================\n",
        "\n",
        "def brute_force(path1: str, path2: str) -> Tuple[bool, List[int]]:\n",
        "    \"\"\"\n",
        "    Brute-force graph isomorphism (Question 1).\n",
        "\n",
        "    Idea:\n",
        "      - Generate all bijections ρ: V1 → V2 (all permutations of {0, ..., n-1}).\n",
        "      - For each permutation, test the isomorphism condition.\n",
        "\n",
        "    Returns:\n",
        "      (True, mapping_list)  if an isomorphism exists,\n",
        "      (False, [])           otherwise.\n",
        "    \"\"\"\n",
        "    adj1 = load_graph(path1)\n",
        "    adj2 = load_graph(path2)\n",
        "\n",
        "    # Quick rejection before heavy search\n",
        "    if not quick_invariants_match(adj1, adj2):\n",
        "        print(False, [])\n",
        "        return False, []\n",
        "\n",
        "    n = len(adj1)\n",
        "\n",
        "    for perm in permutations(range(n)):\n",
        "        mapping = list(perm)\n",
        "        if check_isomorphism_from_mapping(adj1, adj2, mapping):\n",
        "            print(True, mapping)\n",
        "            return True, mapping\n",
        "\n",
        "    print(False, [])\n",
        "    return False, []\n"
      ],
      "metadata": {
        "id": "_G2N9oB_UYZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 4 — Question 2: Backtracking Algorithm\n",
        "\n",
        "This algorithm builds the mapping incrementally:\n",
        "\n",
        "1. Start with node `v1` in `G1`\n",
        "2. Try assigning it to every unused node in `G2`\n",
        "3. After each tentative mapping, check edge-consistency with previously mapped nodes\n",
        "4. If consistent → continue\n",
        "5. If not consistent → undo the assignment (**backtrack**) and try another choice\n",
        "\n",
        "This drastically reduces the search space compared to brute force.\n",
        "\n",
        "### Provided:\n",
        "- `_backtracking_recursive()`\n",
        "- `backtracking(path1, path2)`\n"
      ],
      "metadata": {
        "id": "KpTD2ji5UfZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Section 4 - Question 2: Backtracking\n",
        "# ============================================\n",
        "\n",
        "def _backtracking_recursive(\n",
        "    idx: int,\n",
        "    adj1: List[Set[int]],\n",
        "    adj2: List[Set[int]],\n",
        "    mapping: List[int],\n",
        "    used: List[bool],\n",
        "    order: List[int]\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Recursive helper for backtracking.\n",
        "\n",
        "    Parameters:\n",
        "      idx   : index in 'order' of the node we are mapping now.\n",
        "      order : ordering of vertices in G1, usually [0, 1, ..., n-1].\n",
        "\n",
        "    At step idx:\n",
        "      - Let v1 = order[idx].\n",
        "      - Try each unused vertex v2 in G2 as image.\n",
        "      - Check edge consistency with already-mapped vertices.\n",
        "      - If consistent, recurse; otherwise backtrack.\n",
        "    \"\"\"\n",
        "    n = len(adj1)\n",
        "    if idx == n:\n",
        "        # All vertices are mapped.\n",
        "        return True\n",
        "\n",
        "    v1 = order[idx]\n",
        "\n",
        "    for v2 in range(n):\n",
        "        if used[v2]:\n",
        "            continue\n",
        "\n",
        "        # Tentative assignment v1 -> v2.\n",
        "        mapping[v1] = v2\n",
        "\n",
        "        # Check isomorphism condition for edges involving v1 and already mapped u1.\n",
        "        consistent = True\n",
        "        for u1 in range(n):\n",
        "            if u1 == v1 or mapping[u1] == -1:\n",
        "                continue\n",
        "            u2 = mapping[u1]\n",
        "            edge1 = (u1 in adj1[v1])\n",
        "            edge2 = (u2 in adj2[v2])\n",
        "            if edge1 != edge2:\n",
        "                consistent = False\n",
        "                break\n",
        "\n",
        "        if not consistent:\n",
        "            mapping[v1] = -1\n",
        "            continue\n",
        "\n",
        "        # Continue deeper.\n",
        "        used[v2] = True\n",
        "        if _backtracking_recursive(idx + 1, adj1, adj2, mapping, used, order):\n",
        "            return True\n",
        "        # Backtrack.\n",
        "        used[v2] = False\n",
        "        mapping[v1] = -1\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "def backtracking(path1: str, path2: str) -> Tuple[bool, List[int]]:\n",
        "    \"\"\"\n",
        "    Greedy backtracking algorithm (Question 2).\n",
        "\n",
        "    We map v1, v2, ..., vn one by one and test the isomorphism condition\n",
        "    for the first i vertices at step i.\n",
        "\n",
        "    Returns:\n",
        "      (True, mapping_list)  if an isomorphism exists,\n",
        "      (False, [])           otherwise.\n",
        "    \"\"\"\n",
        "    adj1 = load_graph(path1)\n",
        "    adj2 = load_graph(path2)\n",
        "\n",
        "    if not quick_invariants_match(adj1, adj2):\n",
        "        print(False, [])\n",
        "        return False, []\n",
        "\n",
        "    n = len(adj1)\n",
        "    mapping = [-1] * n\n",
        "    used = [False] * n\n",
        "    order = list(range(n))   # could be changed to a heuristic order if desired.\n",
        "\n",
        "    success = _backtracking_recursive(0, adj1, adj2, mapping, used, order)\n",
        "\n",
        "    if success:\n",
        "        print(True, mapping)\n",
        "        return True, mapping\n",
        "    else:\n",
        "        print(False, [])\n",
        "        return False, []\n"
      ],
      "metadata": {
        "id": "B64PD5iXUa6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 5 — Question 3: Backtracking with Degree Partitioning\n",
        "\n",
        "This improves the previous algorithm:\n",
        "\n",
        "A node in `G1` with degree `d` can only map to nodes in `G2` that also have degree `d`.\n",
        "\n",
        "This reduces the candidate set drastically and speeds up the search.\n",
        "\n",
        "### Provided:\n",
        "- `_degree_backtracking_recursive()`\n",
        "- `degree_backtracking(path1, path2)`\n",
        "- alias: `backtracking_degree = degree_backtracking`\n"
      ],
      "metadata": {
        "id": "mZdW14teUlXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Section 5 - Question 3: Backtracking with degree partitioning\n",
        "# ============================================\n",
        "\n",
        "def _degree_backtracking_recursive(\n",
        "    idx: int,\n",
        "    adj1: List[Set[int]],\n",
        "    adj2: List[Set[int]],\n",
        "    mapping: List[int],\n",
        "    used: List[bool],\n",
        "    order: List[int],\n",
        "    deg1: List[int],\n",
        "    deg2_nodes: Dict[int, List[int]]\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Recursive helper for degree-constrained backtracking.\n",
        "\n",
        "    Only tries candidates in G2 that have the same degree as the current\n",
        "    node v1 in G1.\n",
        "    \"\"\"\n",
        "    n = len(adj1)\n",
        "    if idx == n:\n",
        "        return True\n",
        "\n",
        "    v1 = order[idx]\n",
        "    d = deg1[v1]\n",
        "    candidates = deg2_nodes.get(d, [])\n",
        "\n",
        "    for v2 in candidates:\n",
        "        if used[v2]:\n",
        "            continue\n",
        "\n",
        "        mapping[v1] = v2\n",
        "\n",
        "        # Check consistency with already mapped nodes.\n",
        "        consistent = True\n",
        "        for u1 in range(n):\n",
        "            if u1 == v1 or mapping[u1] == -1:\n",
        "                continue\n",
        "            u2 = mapping[u1]\n",
        "            edge1 = (u1 in adj1[v1])\n",
        "            edge2 = (u2 in adj2[v2])\n",
        "            if edge1 != edge2:\n",
        "                consistent = False\n",
        "                break\n",
        "\n",
        "        if not consistent:\n",
        "            mapping[v1] = -1\n",
        "            continue\n",
        "\n",
        "        used[v2] = True\n",
        "        if _degree_backtracking_recursive(\n",
        "            idx + 1, adj1, adj2, mapping, used, order, deg1, deg2_nodes\n",
        "        ):\n",
        "            return True\n",
        "        used[v2] = False\n",
        "        mapping[v1] = -1\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "def degree_backtracking(path1: str, path2: str) -> Tuple[bool, List[int]]:\n",
        "    \"\"\"\n",
        "    Backtracking with degree partitioning (Question 3).\n",
        "\n",
        "    A node v in G1 with degree d can only map to nodes of degree d in G2.\n",
        "\n",
        "    Returns:\n",
        "      (True, mapping_list)  if isomorphic,\n",
        "      (False, [])           otherwise.\n",
        "    \"\"\"\n",
        "    adj1 = load_graph(path1)\n",
        "    adj2 = load_graph(path2)\n",
        "\n",
        "    if not quick_invariants_match(adj1, adj2):\n",
        "        print(False, [])\n",
        "        return False, []\n",
        "\n",
        "    n = len(adj1)\n",
        "    mapping = [-1] * n\n",
        "    used = [False] * n\n",
        "    order = list(range(n))\n",
        "\n",
        "    deg1 = [len(adj1[v]) for v in range(n)]\n",
        "    deg2 = [len(adj2[v]) for v in range(n)]\n",
        "\n",
        "    # degree -> list of nodes in G2 with that degree\n",
        "    deg2_nodes: Dict[int, List[int]] = {}\n",
        "    for v in range(n):\n",
        "        d = deg2[v]\n",
        "        deg2_nodes.setdefault(d, []).append(v)\n",
        "\n",
        "    success = _degree_backtracking_recursive(\n",
        "        0, adj1, adj2, mapping, used, order, deg1, deg2_nodes\n",
        "    )\n",
        "\n",
        "    if success:\n",
        "        print(True, mapping)\n",
        "        return True, mapping\n",
        "    else:\n",
        "        print(False, [])\n",
        "        return False, []\n",
        "\n",
        "\n",
        "# Alias because the statement names this function backtracking_degree.\n",
        "backtracking_degree = degree_backtracking\n"
      ],
      "metadata": {
        "id": "jBTlPgGRUiPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backtracking_degree(path1: str, path2: str):\n",
        "    \"\"\"\n",
        "    Wrapper to match the required function name in the assignment.\n",
        "    It simply calls degree_backtracking under the hood.\n",
        "    \"\"\"\n",
        "    return degree_backtracking(path1, path2)"
      ],
      "metadata": {
        "id": "0DHsiGWUhy84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 6 — Question 4: Stable Partitioning (Weisfeiler–Leman Refinement)\n",
        "\n",
        "This section implements the classical 1-dimensional Weisfeiler–Leman refinement:\n",
        "\n",
        "1. Start from the degree partition\n",
        "2. Repeatedly refine parts:\n",
        "   - nodes remain in the same part only if they have the same multiset\n",
        "     of neighbor-part labels\n",
        "3. Stop when the partition does not change anymore (stable partition)\n",
        "\n",
        "### Provided:\n",
        "- `_refine_partition_once()`\n",
        "- `stable_partition(adj)`\n"
      ],
      "metadata": {
        "id": "5cmRli24UsIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Section 6 - Question 4: Stable partition (single graph)\n",
        "# ============================================\n",
        "\n",
        "def _refine_partition_once(\n",
        "    adj: List[Set[int]],\n",
        "    node_to_part: List[int],\n",
        "    parts: List[List[int]]\n",
        ") -> Tuple[List[int], List[List[int]]]:\n",
        "    \"\"\"\n",
        "    Perform one refinement step of the partition for a single graph.\n",
        "\n",
        "    For each existing part:\n",
        "      - group the nodes inside that part according to the sorted multiset\n",
        "        of neighbor-part IDs.\n",
        "    \"\"\"\n",
        "    n = len(adj)\n",
        "    new_node_to_part = [-1] * n\n",
        "    new_parts: List[List[int]] = []\n",
        "\n",
        "    for old_pid, nodes in enumerate(parts):\n",
        "        sig_to_subpart: Dict[Tuple[int, ...], List[int]] = {}\n",
        "\n",
        "        for v in nodes:\n",
        "            neighbor_parts = sorted(node_to_part[nb] for nb in adj[v])\n",
        "            sig = tuple(neighbor_parts)\n",
        "            sig_to_subpart.setdefault(sig, []).append(v)\n",
        "\n",
        "        for sub in sig_to_subpart.values():\n",
        "            new_pid = len(new_parts)\n",
        "            new_parts.append(sub)\n",
        "            for v in sub:\n",
        "                new_node_to_part[v] = new_pid\n",
        "\n",
        "    return new_node_to_part, new_parts\n",
        "\n",
        "\n",
        "def stable_partition(\n",
        "    adj: List[Set[int]]\n",
        ") -> Tuple[List[int], List[List[int]]]:\n",
        "    \"\"\"\n",
        "    Compute the stable partition of a graph, starting from its degree partition.\n",
        "\n",
        "    We repeatedly refine the partition until it stops changing.\n",
        "    This is the 1-dimensional Weisfeiler–Leman color refinement.\n",
        "    \"\"\"\n",
        "    node_to_part, parts = _build_degree_partition(adj)\n",
        "\n",
        "    while True:\n",
        "        new_node_to_part, new_parts = _refine_partition_once(adj, node_to_part, parts)\n",
        "        if new_node_to_part == node_to_part:\n",
        "            return node_to_part, parts\n",
        "        node_to_part, parts = new_node_to_part, new_parts\n"
      ],
      "metadata": {
        "id": "9Fo6kE1aUoQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 7 — Question 5: Stable Double Partitioning\n",
        "\n",
        "This extends stable partitioning to **two graphs simultaneously**.\n",
        "\n",
        "Two partitions are compatible if:\n",
        "\n",
        "- they have the same number of parts\n",
        "- each part has the same size\n",
        "- if a part splits in `G1`, the corresponding part must split the same way in `G2`\n",
        "\n",
        "If at any refinement step compatibility fails → the graphs cannot be isomorphic.\n",
        "\n",
        "### Provided:\n",
        "- `stable_double_partition(...)`\n"
      ],
      "metadata": {
        "id": "29t2YhvCUxyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Section 7 - Question 5: Stable double partition (two graphs)\n",
        "# ============================================\n",
        "\n",
        "def stable_double_partition(\n",
        "    adj1: List[Set[int]],\n",
        "    node_to_part1: List[int],\n",
        "    parts1: List[List[int]],\n",
        "    adj2: List[Set[int]],\n",
        "    node_to_part2: List[int],\n",
        "    parts2: List[List[int]]\n",
        ") -> Union[bool, Tuple[List[int], List[List[int]], List[int], List[List[int]]]]:\n",
        "    \"\"\"\n",
        "    Refine partitions of G1 and G2 simultaneously until they become\n",
        "    stable and remain compatible, or detect incompatibility.\n",
        "\n",
        "    Compatibility conditions:\n",
        "      - Same number of parts.\n",
        "      - For each part j: |P1[j]| = |P2[j]|.\n",
        "      - When a part j is split into subparts in G1, the corresponding part j\n",
        "        in G2 must split into subparts with the same signatures and sizes.\n",
        "\n",
        "    Returns:\n",
        "      False if no compatible stable partitions exist, or\n",
        "      (node_to_part1, parts1, node_to_part2, parts2) for the final stable partitions.\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        if len(parts1) != len(parts2):\n",
        "            return False\n",
        "\n",
        "        num_parts = len(parts1)\n",
        "        for pid in range(num_parts):\n",
        "            if len(parts1[pid]) != len(parts2[pid]):\n",
        "                return False\n",
        "\n",
        "        changed = False\n",
        "        new_node_to_part1 = [-1] * len(adj1)\n",
        "        new_node_to_part2 = [-1] * len(adj2)\n",
        "        new_parts1: List[List[int]] = []\n",
        "        new_parts2: List[List[int]] = []\n",
        "\n",
        "        for pid in range(num_parts):\n",
        "            nodes1 = parts1[pid]\n",
        "            nodes2 = parts2[pid]\n",
        "\n",
        "            sig_to_nodes1: Dict[Tuple[int, ...], List[int]] = {}\n",
        "            sig_to_nodes2: Dict[Tuple[int, ...], List[int]] = {}\n",
        "\n",
        "            for v in nodes1:\n",
        "                neighbor_parts = sorted(node_to_part1[nb] for nb in adj1[v])\n",
        "                sig = tuple(neighbor_parts)\n",
        "                sig_to_nodes1.setdefault(sig, []).append(v)\n",
        "\n",
        "            for v in nodes2:\n",
        "                neighbor_parts = sorted(node_to_part2[nb] for nb in adj2[v])\n",
        "                sig = tuple(neighbor_parts)\n",
        "                sig_to_nodes2.setdefault(sig, []).append(v)\n",
        "\n",
        "            # They must have the same set of signatures.\n",
        "            if set(sig_to_nodes1.keys()) != set(sig_to_nodes2.keys()):\n",
        "                return False\n",
        "\n",
        "            # Deterministic ordering of signatures.\n",
        "            for sig in sorted(sig_to_nodes1.keys(), key=lambda x: (len(x), x)):\n",
        "                group1 = sig_to_nodes1[sig]\n",
        "                group2 = sig_to_nodes2[sig]\n",
        "\n",
        "                if len(group1) != len(group2):\n",
        "                    return False\n",
        "\n",
        "                new_pid = len(new_parts1)\n",
        "                new_parts1.append(group1)\n",
        "                new_parts2.append(group2)\n",
        "\n",
        "                for v in group1:\n",
        "                    new_node_to_part1[v] = new_pid\n",
        "                for v in group2:\n",
        "                    new_node_to_part2[v] = new_pid\n",
        "\n",
        "            if len(sig_to_nodes1) > 1:\n",
        "                changed = True\n",
        "\n",
        "        if not changed:\n",
        "            # Partitions are stable and compatible.\n",
        "            return new_node_to_part1, new_parts1, new_node_to_part2, new_parts2\n",
        "\n",
        "        node_to_part1, parts1 = new_node_to_part1, new_parts1\n",
        "        node_to_part2, parts2 = new_node_to_part2, new_parts2\n"
      ],
      "metadata": {
        "id": "C_YZ4IHjUzSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 8 — Question 6: Weisfeiler–Leman Backtracking\n",
        "\n",
        "This is the most powerful algorithm in the project.\n",
        "\n",
        "Steps:\n",
        "1. Build degree partitions for both graphs\n",
        "2. Refine them using stable double partitioning\n",
        "3. During backtracking:\n",
        "   - a node in part `j` can only map to nodes in part `j`\n",
        "   - once a mapping `v1 → v2` is fixed:\n",
        "     - put each into its own singleton part\n",
        "     - refine again using double partitioning\n",
        "4. If refinement collapses → backtrack\n",
        "\n",
        "This combines combinatorial pruning + structural refinement.\n",
        "\n",
        "### Provided:\n",
        "- `_split_singleton_part()`\n",
        "- `_wl_backtracking_recursive()`\n",
        "- `weisfeiler_leman_backtracking(path1, path2)`\n"
      ],
      "metadata": {
        "id": "i37bq5h8U1uI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Section 8 — Question 6: Weisfeiler–Leman backtracking\n",
        "# ============================================\n",
        "\n",
        "from typing import Optional\n",
        "def _split_singleton_part(\n",
        "    node_to_part: List[int],\n",
        "    parts: List[List[int]],\n",
        "    v: int\n",
        ") -> Tuple[List[int], List[List[int]]]:\n",
        "    \"\"\"\n",
        "    Ensure that node v is in its own singleton part.\n",
        "\n",
        "    If its part already has size 1, do nothing.\n",
        "    Otherwise, split that part into:\n",
        "      - the remainder (old part without v)\n",
        "      - a new singleton part {v}\n",
        "    \"\"\"\n",
        "    node_to_part = node_to_part[:]              # copy\n",
        "    parts = [lst[:] for lst in parts]           # deep copy\n",
        "\n",
        "    old_pid = node_to_part[v]\n",
        "    old_nodes = parts[old_pid]\n",
        "\n",
        "    if len(old_nodes) == 1:\n",
        "        return node_to_part, parts\n",
        "\n",
        "    remaining = [x for x in old_nodes if x != v]\n",
        "    parts[old_pid] = remaining\n",
        "\n",
        "    new_pid = len(parts)\n",
        "    parts.append([v])\n",
        "    node_to_part[v] = new_pid\n",
        "\n",
        "    return node_to_part, parts\n",
        "\n",
        "\n",
        "def _mapping_from_partitions(\n",
        "    adj1: List[Set[int]],\n",
        "    adj2: List[Set[int]],\n",
        "    parts1: List[List[int]],\n",
        "    parts2: List[List[int]]\n",
        ") -> Optional[List[int]]:\n",
        "    \"\"\"\n",
        "    If the partitions are already 'discrete enough', derive a mapping\n",
        "    directly from them and verify it. This is valid for any size and is\n",
        "    just an optimization: no branching is needed if WL has already\n",
        "    distinguished all vertices.\n",
        "    \"\"\"\n",
        "    if len(parts1) != len(parts2):\n",
        "        return None\n",
        "\n",
        "    n = len(adj1)\n",
        "    mapping = [-1] * n\n",
        "\n",
        "    for pid in range(len(parts1)):\n",
        "        block1 = sorted(parts1[pid])\n",
        "        block2 = sorted(parts2[pid])\n",
        "        if len(block1) != len(block2):\n",
        "            return None\n",
        "        for i in range(len(block1)):\n",
        "            mapping[block1[i]] = block2[i]\n",
        "\n",
        "    if check_isomorphism_from_mapping(adj1, adj2, mapping):\n",
        "        return mapping\n",
        "    return None\n",
        "\n",
        "\n",
        "def _wl_backtracking_recursive(\n",
        "    idx: int,\n",
        "    adj1: List[Set[int]],\n",
        "    adj2: List[Set[int]],\n",
        "    mapping: List[int],\n",
        "    used: List[bool],\n",
        "    order: List[int],\n",
        "    node_to_part1: List[int],\n",
        "    parts1: List[List[int]],\n",
        "    node_to_part2: List[int],\n",
        "    parts2: List[List[int]],\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Recursive helper for Weisfeiler–Leman-based backtracking.\n",
        "\n",
        "    Invariant:\n",
        "      - Part j in G1 corresponds to part j in G2.\n",
        "      - A node in part j of G1 may only be mapped to unused nodes\n",
        "        in the same part j of G2.\n",
        "    After each mapping v1 -> v2:\n",
        "      - Put both into singleton parts.\n",
        "      - Refine again with stable_double_partition.\n",
        "    \"\"\"\n",
        "    n = len(adj1)\n",
        "    if idx == n:\n",
        "        return True\n",
        "\n",
        "    # Optional micro-optimization: if at some stage all parts are singletons,\n",
        "    # we can read off the mapping directly and stop.\n",
        "    if all(len(block) == 1 for block in parts1):\n",
        "        direct_mapping = _mapping_from_partitions(adj1, adj2, parts1, parts2)\n",
        "        if direct_mapping is not None:\n",
        "            mapping[:] = direct_mapping\n",
        "            return True\n",
        "\n",
        "    v1 = order[idx]\n",
        "    if mapping[v1] != -1:\n",
        "        return _wl_backtracking_recursive(\n",
        "            idx + 1, adj1, adj2,\n",
        "            mapping, used, order,\n",
        "            node_to_part1, parts1,\n",
        "            node_to_part2, parts2\n",
        "        )\n",
        "\n",
        "    part_id = node_to_part1[v1]\n",
        "\n",
        "    # Candidates: unused vertices in the same WL part in G2\n",
        "    candidates = [v2 for v2 in parts2[part_id] if not used[v2]]\n",
        "\n",
        "    for v2 in candidates:\n",
        "        # Local consistency check w.r.t. already mapped vertices\n",
        "        ok = True\n",
        "        for u1 in range(n):\n",
        "            if mapping[u1] == -1:\n",
        "                continue\n",
        "            u2 = mapping[u1]\n",
        "            if (u1 in adj1[v1]) != (u2 in adj2[v2]):\n",
        "                ok = False\n",
        "                break\n",
        "        if not ok:\n",
        "            continue\n",
        "\n",
        "        # Tentatively extend mapping\n",
        "        mapping[v1] = v2\n",
        "        used[v2] = True\n",
        "\n",
        "        # Force v1 and v2 into singleton parts\n",
        "        ntp1_new, p1_new = _split_singleton_part(node_to_part1, parts1, v1)\n",
        "        ntp2_new, p2_new = _split_singleton_part(node_to_part2, parts2, v2)\n",
        "\n",
        "        # Refine both partitions together\n",
        "        refined = stable_double_partition(\n",
        "            adj1, ntp1_new, p1_new,\n",
        "            adj2, ntp2_new, p2_new\n",
        "        )\n",
        "\n",
        "        if refined is not False:\n",
        "            (ntp1_ref, p1_ref, ntp2_ref, p2_ref) = refined\n",
        "\n",
        "            if _wl_backtracking_recursive(\n",
        "                idx + 1, adj1, adj2,\n",
        "                mapping, used, order,\n",
        "                ntp1_ref, p1_ref,\n",
        "                ntp2_ref, p2_ref\n",
        "            ):\n",
        "                return True\n",
        "\n",
        "        # Backtrack\n",
        "        mapping[v1] = -1\n",
        "        used[v2] = False\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "def weisfeiler_leman_backtracking(path1: str, path2: str) -> Tuple[bool, List[int]]:\n",
        "    \"\"\"\n",
        "    Weisfeiler–Leman backtracking (Question 6).\n",
        "\n",
        "    1. Load graphs and check quick invariants.\n",
        "    2. Build degree partitions for both graphs.\n",
        "    3. Refine them simultaneously with stable_double_partition to obtain\n",
        "       compatible stable partitions.\n",
        "    4. Use these partitions to guide a backtracking search:\n",
        "       - v in part j of G1 can only map to vertices in part j of G2.\n",
        "       - After each mapping, place both into singleton parts and refine again.\n",
        "    5. If we reach a full mapping, return it; otherwise return False, [].\n",
        "    \"\"\"\n",
        "    adj1 = load_graph(path1)\n",
        "    adj2 = load_graph(path2)\n",
        "\n",
        "    if not quick_invariants_match(adj1, adj2):\n",
        "        print(False, [])\n",
        "        return False, []\n",
        "\n",
        "    n = len(adj1)\n",
        "\n",
        "    # 1) Degree partitions\n",
        "    node_to_part1, parts1 = _build_degree_partition(adj1)\n",
        "    node_to_part2, parts2 = _build_degree_partition(adj2)\n",
        "\n",
        "    # 2) WL refinement to stable compatible partitions\n",
        "    refined = stable_double_partition(\n",
        "        adj1, node_to_part1, parts1,\n",
        "        adj2, node_to_part2, parts2\n",
        "    )\n",
        "\n",
        "    if refined is False:\n",
        "        print(False, [])\n",
        "        return False, []\n",
        "\n",
        "    node_to_part1_ref, parts1_ref, node_to_part2_ref, parts2_ref = refined\n",
        "\n",
        "    # 3) If WL refinement already distinguishes all vertices, read off mapping\n",
        "    if all(len(block) == 1 for block in parts1_ref):\n",
        "        mapping = _mapping_from_partitions(adj1, adj2, parts1_ref, parts2_ref)\n",
        "        if mapping is not None:\n",
        "            print(True, mapping)\n",
        "            return True, mapping\n",
        "        # If something went wrong, fall back to backtracking.\n",
        "\n",
        "    # 4) WL-guided backtracking\n",
        "    mapping = [-1] * n\n",
        "    used = [False] * n\n",
        "\n",
        "    # Order: vertices in smaller parts first (more constrained), then by degree.\n",
        "    order = sorted(\n",
        "        range(n),\n",
        "        key=lambda v: (len(parts1_ref[node_to_part1_ref[v]]), -len(adj1[v]))\n",
        "    )\n",
        "\n",
        "    success = _wl_backtracking_recursive(\n",
        "        0, adj1, adj2,\n",
        "        mapping, used, order,\n",
        "        node_to_part1_ref, parts1_ref,\n",
        "        node_to_part2_ref, parts2_ref\n",
        "    )\n",
        "\n",
        "    if success:\n",
        "        print(True, mapping)\n",
        "        return True, mapping\n",
        "    else:\n",
        "        print(False, [])\n",
        "        return False, []\n"
      ],
      "metadata": {
        "id": "F5KGx7-OPVNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Section 9 – Testing Weisfeiler–Leman Backtracking\n",
        "# ============================================\n",
        "\n",
        "def test_wl_on_pair(name: str, path1: str, path2: str):\n",
        "    \"\"\"\n",
        "    Helper to test weisfeiler_leman_backtracking on a single pair of graphs.\n",
        "    \"\"\"\n",
        "    print(f\"\\n===== {name} =====\")\n",
        "    print(f\"Files: {path1}  vs  {path2}\")\n",
        "    result = weisfeiler_leman_backtracking(path1, path2)\n",
        "    print(\"Returned:\", result)\n",
        "\n",
        "\n",
        "# ---- Small / medium graphs (should already exist from earlier sections) ----\n",
        "\n",
        "# Example: small 4-node isomorphic pair\n",
        "# g1.txt, g2.txt were your very first example used in Section 2/3.\n",
        "try:\n",
        "    test_wl_on_pair(\"Small 4-node isomorphic (g1 vs g2)\", \"g1.txt\", \"g2.txt\")\n",
        "except FileNotFoundError:\n",
        "    print(\"g1.txt / g2.txt not found – skip this test.\")\n",
        "\n",
        "# Example: 6-node cycle isomorphic pair\n",
        "try:\n",
        "    test_wl_on_pair(\"Cycle (6 nodes, isomorphic)\", \"cycle6_a.txt\", \"cycle6_b.txt\")\n",
        "except FileNotFoundError:\n",
        "    print(\"cycle6_a.txt / cycle6_b.txt not found – skip this test.\")\n",
        "\n",
        "# Example: 10-node tree isomorphic pair\n",
        "try:\n",
        "    test_wl_on_pair(\"Tree (10 nodes, isomorphic)\", \"tree10_a.txt\", \"tree10_b.txt\")\n",
        "except FileNotFoundError:\n",
        "    print(\"tree10_a.txt / tree10_b.txt not found – skip this test.\")\n",
        "\n",
        "\n",
        "# ---- Large graphs (2000 nodes) – from the generation cell in Section 10 ----\n",
        "# These files were created earlier as:\n",
        "#   large_G.txt        – a random graph G\n",
        "#   large_G_perm.txt   – a permuted (isomorphic) copy of G\n",
        "#   large_H.txt        – another random graph, not isomorphic to G\n",
        "\n",
        "try:\n",
        "    test_wl_on_pair(\"Large graphs (2000 nodes, isomorphic: G vs G_perm)\",\n",
        "                    \"large_G.txt\", \"large_G_perm.txt\")\n",
        "except FileNotFoundError:\n",
        "    print(\"large_G.txt / large_G_perm.txt not found – skip this test.\")\n",
        "\n",
        "try:\n",
        "    test_wl_on_pair(\"Large graphs (2000 nodes, non-isomorphic: G vs H)\",\n",
        "                    \"large_G.txt\", \"large_H.txt\")\n",
        "except FileNotFoundError:\n",
        "    print(\"large_G.txt / large_H.txt not found – skip this test.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTgk6rYIUI50",
        "outputId": "04dcdd3c-6417-4e41-ffcd-1e7933c00459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Small 4-node isomorphic (g1 vs g2) =====\n",
            "Files: g1.txt  vs  g2.txt\n",
            "True [1, 2, 0, 3]\n",
            "Returned: (True, [1, 2, 0, 3])\n",
            "\n",
            "===== Cycle (6 nodes, isomorphic) =====\n",
            "Files: cycle6_a.txt  vs  cycle6_b.txt\n",
            "True [0, 2, 4, 1, 5, 3]\n",
            "Returned: (True, [0, 2, 4, 1, 5, 3])\n",
            "\n",
            "===== Tree (10 nodes, isomorphic) =====\n",
            "Files: tree10_a.txt  vs  tree10_b.txt\n",
            "True [2, 5, 6, 3, 8, 7, 9, 1, 4, 0]\n",
            "Returned: (True, [2, 5, 6, 3, 8, 7, 9, 1, 4, 0])\n",
            "\n",
            "===== Large graphs (2000 nodes, isomorphic: G vs G_perm) =====\n",
            "Files: large_G.txt  vs  large_G_perm.txt\n",
            "True [601, 1240, 244, 1599, 655, 1307, 292, 186, 84, 798, 1482, 1392, 1370, 1759, 918, 7, 440, 66, 1228, 820, 1516, 1506, 139, 1489, 806, 1785, 1173, 62, 1662, 1391, 639, 289, 1316, 1526, 721, 1645, 553, 567, 1040, 675, 504, 1453, 853, 1352, 1451, 1083, 110, 1427, 748, 1367, 229, 1978, 1202, 201, 208, 910, 389, 1863, 138, 457, 1820, 1330, 1001, 1078, 64, 1568, 1160, 1163, 1894, 94, 1929, 219, 1711, 1087, 1728, 438, 707, 942, 651, 1974, 1622, 1792, 1264, 1593, 767, 281, 211, 1230, 43, 1357, 542, 1758, 1425, 203, 126, 574, 1500, 1943, 118, 1134, 1606, 231, 1493, 1517, 644, 1814, 1006, 1355, 325, 185, 916, 983, 586, 197, 632, 642, 189, 703, 1406, 1053, 561, 55, 1212, 261, 271, 609, 686, 934, 1955, 864, 592, 1091, 471, 702, 1644, 168, 1232, 1333, 1440, 1227, 1254, 955, 1637, 782, 1535, 174, 1183, 128, 1588, 1021, 73, 47, 1332, 755, 1842, 981, 1756, 1399, 306, 937, 952, 618, 1041, 673, 659, 368, 119, 948, 1603, 114, 1020, 1898, 527, 1110, 311, 1274, 564, 706, 688, 776, 810, 979, 1511, 1924, 1981, 1176, 856, 1199, 502, 1499, 1170, 635, 1618, 1616, 713, 693, 1300, 1858, 87, 1004, 1916, 1090, 196, 743, 304, 1968, 1565, 1409, 1024, 1382, 569, 431, 1679, 1667, 1691, 1876, 76, 1276, 288, 829, 397, 1928, 1445, 1709, 1233, 764, 1346, 1904, 1, 1248, 960, 681, 258, 931, 477, 809, 1545, 565, 1868, 97, 1740, 1412, 1921, 1433, 720, 754, 96, 80, 1747, 270, 1380, 1696, 470, 1456, 1467, 1704, 1991, 883, 940, 768, 1604, 824, 1137, 57, 821, 1379, 1735, 1284, 1471, 1852, 766, 1575, 775, 520, 984, 199, 1470, 990, 731, 626, 978, 2, 614, 1631, 161, 1267, 815, 1088, 409, 407, 454, 1159, 1847, 1918, 420, 297, 723, 294, 1902, 296, 1015, 160, 1217, 582, 973, 1947, 167, 660, 453, 299, 730, 1873, 1431, 560, 1029, 423, 1428, 1538, 1187, 1509, 21, 70, 1781, 1849, 1485, 1035, 1398, 1394, 146, 215, 967, 1275, 1988, 1361, 625, 1039, 1584, 907, 357, 428, 77, 1528, 627, 1345, 265, 1990, 875, 1520, 1576, 298, 9, 277, 1158, 757, 1393, 547, 1895, 1903, 85, 276, 1459, 1887, 1641, 1940, 424, 667, 1560, 932, 1547, 1802, 1434, 1686, 1650, 1429, 1744, 451, 640, 1551, 163, 487, 181, 307, 774, 780, 938, 1405, 1627, 239, 1725, 461, 1822, 1096, 1818, 257, 1893, 792, 379, 761, 1417, 1474, 1654, 328, 141, 1052, 478, 1181, 1670, 712, 1901, 1185, 629, 1642, 46, 1258, 145, 314, 814, 840, 1524, 1823, 1374, 1325, 1475, 122, 1097, 1003, 649, 1200, 1285, 595, 176, 1498, 1005, 391, 1362, 1794, 606, 102, 1515, 459, 291, 1438, 1710, 1055, 518, 1410, 899, 15, 1120, 846, 728, 1834, 1263, 831, 1685, 90, 1786, 427, 1614, 224, 1468, 634, 668, 852, 488, 677, 266, 1555, 985, 1824, 1869, 1478, 811, 753, 1598, 1967, 1570, 49, 1400, 832, 783, 1435, 1195, 1386, 381, 1143, 804, 1578, 1890, 1810, 879, 1505, 1591, 1125, 353, 1656, 933, 1961, 1750, 765, 1507, 1290, 807, 1207, 619, 823, 613, 480, 715, 225, 375, 539, 1156, 1996, 1790, 844, 1395, 1038, 1797, 1783, 593, 1889, 78, 51, 1080, 1179, 874, 808, 1793, 1304, 661, 947, 1826, 1883, 1537, 683, 1242, 1397, 1803, 1502, 1518, 1201, 854, 154, 744, 268, 1231, 346, 499, 269, 144, 1049, 1534, 641, 1180, 1951, 1387, 68, 1186, 530, 1311, 313, 796, 1128, 1594, 801, 1152, 194, 1457, 1260, 718, 182, 1138, 987, 1184, 1579, 274, 975, 1715, 891, 1776, 1278, 1269, 1016, 750, 1229, 1562, 72, 1882, 394, 1571, 1064, 1632, 484, 610, 1312, 1255, 1726, 98, 1681, 152, 489, 1871, 1780, 1853, 602, 408, 1956, 350, 1326, 1771, 29, 726, 1464, 1132, 1542, 902, 482, 1338, 1013, 1472, 1762, 666, 216, 370, 267, 386, 320, 805, 1075, 11, 1620, 1178, 383, 220, 360, 1302, 393, 1761, 1597, 1881, 1891, 1245, 452, 1210, 241, 1265, 559, 704, 1600, 550, 1949, 558, 248, 1321, 115, 1131, 631, 873, 1356, 503, 1683, 63, 392, 1058, 1608, 264, 83, 1832, 1610, 251, 1937, 316, 169, 58, 19, 508, 1581, 485, 736, 546, 830, 1706, 663, 354, 127, 1465, 1155, 1997, 443, 850, 26, 137, 575, 1025, 34, 1366, 507, 490, 1574, 170, 1558, 588, 412, 638, 1605, 1907, 448, 828, 1768, 1836, 134, 1462, 745, 1073, 598, 25, 1318, 95, 117, 1659, 724, 684, 1753, 458, 326, 1105, 74, 928, 319, 1741, 308, 1680, 61, 1806, 551, 351, 1845, 1837, 444, 848, 1854, 1350, 1114, 1856, 88, 1286, 223, 936, 1979, 1323, 1732, 1589, 1280, 1719, 1439, 1566, 380, 1193, 1444, 285, 1870, 436, 1376, 1171, 279, 1716, 286, 1072, 1309, 473, 173, 962, 909, 165, 1585, 1595, 930, 347, 1821, 1602, 1619, 300, 254, 150, 30, 236, 376, 578, 773, 1488, 0, 777, 48, 131, 646, 1147, 1948, 611, 1945, 1329, 228, 240, 465, 878, 917, 399, 958, 1225, 456, 441, 969, 1766, 922, 964, 1754, 860, 591, 491, 1162, 414, 1550, 23, 1107, 1982, 1795, 1463, 1266, 791, 345, 739, 1121, 1689, 1993, 1104, 1660, 1262, 1223, 1327, 1666, 1319, 1384, 1054, 1791, 579, 12, 125, 1874, 842, 1413, 1496, 1867, 714, 1023, 337, 1455, 1351, 1422, 1033, 665, 1688, 1504, 604, 317, 630, 109, 1426, 571, 1859, 348, 1133, 1919, 27, 903, 442, 205, 1888, 1077, 689, 965, 1243, 404, 302, 1122, 1226, 1247, 446, 888, 970, 905, 1424, 1303, 243, 664, 1194, 253, 1051, 1712, 177, 1182, 1674, 1703, 993, 1407, 1079, 1165, 633, 417, 838, 1115, 1784, 669, 362, 1118, 129, 679, 1042, 496, 1731, 1734, 1727, 1069, 1615, 1738, 1011, 1339, 1770, 540, 481, 1139, 1446, 494, 1414, 581, 1331, 1288, 421, 1093, 1423, 38, 426, 1733, 400, 1640, 1126, 402, 1841, 1494, 20, 1638, 890, 1559, 207, 1092, 1378, 425, 566, 1141, 837, 1102, 1964, 519, 607, 1772, 272, 13, 997, 1995, 549, 788, 1081, 309, 886, 636, 999, 365, 803, 1116, 991, 887, 492, 107, 556, 648, 1421, 645, 213, 781, 756, 1998, 332, 871, 1460, 467, 1839, 623, 1941, 373, 711, 1561, 65, 1237, 1531, 1512, 105, 1161, 1909, 1621, 1774, 1148, 511, 894, 1353, 868, 82, 855, 1416, 986, 155, 1014, 1501, 1611, 1124, 963, 89, 1992, 385, 212, 1801, 290, 103, 198, 1816, 327, 1671, 995, 1580, 1596, 847, 1101, 1553, 183, 813, 1466, 1913, 1063, 324, 851, 1569, 210, 256, 841, 1009, 1860, 1819, 227, 384, 318, 1342, 1612, 361, 162, 1415, 1617, 616, 411, 1623, 543, 410, 260, 1855, 483, 418, 1592, 996, 920, 941, 108, 857, 858, 1648, 548, 682, 1811, 1324, 992, 1065, 1668, 1146, 329, 976, 1724, 915, 1279, 147, 1939, 71, 524, 797, 972, 1987, 1925, 1554, 521, 1363, 1450, 193, 1865, 1008, 156, 1673, 44, 1573, 135, 142, 40, 1368, 1539, 430, 552, 1022, 1403, 1510, 1717, 512, 1957, 628, 1046, 897, 1866, 526, 1970, 323, 535, 1838, 10, 1910, 692, 949, 214, 746, 1256, 1751, 52, 1341, 557, 747, 1371, 338, 1544, 226, 235, 516, 834, 1900, 1214, 101, 1789, 892, 1829, 789, 1787, 1246, 445, 1962, 1692, 1532, 1757, 1007, 221, 464, 784, 1885, 1111, 833, 1779, 339, 1358, 1389, 1381, 1609, 1514, 116, 495, 819, 382, 906, 1935, 405, 696, 674, 1808, 876, 1665, 171, 880, 1150, 1830, 882, 534, 1402, 1848, 705, 396, 770, 700, 1476, 56, 100, 364, 374, 1094, 1283, 1175, 1775, 28, 468, 157, 1960, 1322, 35, 760, 1773, 1973, 1028, 1613, 1944, 1306, 1208, 845, 1745, 242, 901, 1142, 372, 680, 1934, 204, 1086, 1273, 1443, 1699, 1032, 608, 570, 1736, 1864, 1190, 1984, 924, 1213, 403, 790, 99, 1630, 872, 1931, 1983, 1112, 867, 1763, 151, 1906, 1359, 1383, 200, 1714, 287, 787, 310, 1556, 415, 729, 195, 1365, 1722, 919, 799, 1169, 184, 1282, 959, 358, 1503, 439, 862, 333, 900, 1281, 1676, 172, 1344, 1700, 1567, 121, 1705, 133, 717, 1335, 859, 1664, 1624, 1196, 994, 159, 124, 1224, 1663, 1721, 1390, 671, 1164, 690, 676, 37, 1586, 758, 67, 1840, 749, 1755, 1525, 599, 59, 740, 416, 1135, 652, 1533, 727, 1508, 33, 771, 500, 1635, 1843, 587, 1582, 939, 419, 1197, 1268, 1235, 966, 708, 1718, 1639, 525, 522, 510, 621, 295, 1295, 826, 1036, 1012, 50, 349, 1099, 1375, 79, 1952, 1694, 1297, 1813, 1188, 953, 1815, 1742, 506, 590, 935, 1252, 1454, 6, 1034, 1986, 1950, 1259, 1010, 654, 861, 1442, 330, 1629, 732, 1634, 1976, 1479, 60, 437, 1529, 355, 238, 1541, 1372, 532, 974, 123, 1349, 1914, 301, 312, 921, 1633, 1221, 1222, 1850, 282, 923, 112, 785, 554, 1153, 1167, 1625, 1026, 1060, 1799, 472, 1315, 751, 1291, 1234, 904, 8, 233, 1432, 1729, 908, 1452, 149, 786, 1677, 1684, 1626, 1946, 42, 1752, 1203, 1590, 497, 1292, 954, 1204, 24, 284, 1061, 344, 793, 1441, 501, 1270, 1154, 1932, 515, 1144, 1082, 321, 536, 1701, 1687, 1206, 388, 1037, 390, 1314, 255, 1765, 998, 1448, 5, 1458, 709, 178, 863, 293, 250, 1340, 1437, 1317, 1076, 1149, 528, 132, 334, 1513, 1880, 800, 1328, 1563, 1886, 1098, 657, 1100, 545, 759, 1697, 1702, 1861, 772, 741, 1805, 1334, 1636, 589, 662, 1669, 1980, 1965, 1419, 1833, 143, 603, 1106, 977, 1540, 1646, 218, 474, 1661, 432, 1954, 1048, 81, 1166, 322, 576, 1377, 568, 1800, 982, 1972, 1804, 45, 1447, 1113, 1045, 22, 1123, 597, 1189, 140, 1923, 643, 1056, 209, 1936, 1369, 192, 1927, 1922, 925, 1490, 263, 1043, 1737, 1846, 31, 1108, 1396, 734, 563, 600, 584, 435, 1999, 1851, 653, 1348, 769, 447, 130, 763, 697, 913, 670, 187, 53, 450, 1296, 1047, 509, 615, 305, 951, 1145, 234, 369, 1354, 1491, 14, 1933, 869, 943, 988, 1027, 401, 1523, 1449, 1129, 449, 1966, 1401, 1343, 1920, 1788, 1938, 1074, 1461, 1748, 656, 585, 1930, 433, 1767, 1211, 1157, 1373, 694, 562, 1151, 1812, 1828, 687, 188, 136, 1653, 303, 1536, 1827, 331, 91, 1360, 573, 1272, 32, 968, 191, 1647, 93, 1089, 1879, 1168, 816, 1483, 104, 1899, 455, 1031, 957, 961, 206, 356, 1469, 166, 120, 1530, 1844, 1172, 1018, 16, 1953, 232, 914, 818, 1127, 1798, 1958, 283, 1320, 1657, 839, 710, 460, 672, 1989, 1298, 898, 691, 572, 1577, 158, 617, 1070, 54, 1643, 1130, 1713, 1017, 612, 1877, 1878, 1905, 1862, 779, 1301, 1607, 18, 912, 637, 1926, 1103, 1977, 1884, 1236, 893, 1497, 1289, 1136, 69, 825, 434, 927, 971, 827, 1743, 1239, 1308, 1109, 605, 594, 1218, 885, 980, 493, 180, 387, 202, 1095, 1249, 1572, 1778, 335, 555, 259, 1963, 413, 106, 1549, 1675, 733, 41, 75, 1067, 537, 685, 929, 4, 889, 377, 1305, 1219, 367, 1198, 737, 1892, 812, 92, 1293, 1271, 1030, 725, 1519, 1652, 398, 1215, 1277, 486, 505, 1875, 1764, 1477, 1244, 1693, 1896, 658, 866, 624, 742, 1310, 1068, 245, 541, 596, 1825, 822, 1002, 865, 1411, 950, 1730, 1796, 577, 278, 1253, 735, 1527, 1174, 1543, 849, 1299, 835, 36, 476, 475, 1708, 252, 795, 363, 371, 1807, 738, 945, 529, 1487, 336, 469, 513, 1912, 1672, 1975, 1220, 463, 989, 111, 378, 1050, 1385, 222, 498, 1552, 514, 1084, 802, 1777, 1522, 896, 1388, 1287, 1059, 533, 695, 1749, 1192, 1336, 1492, 1628, 1085, 1746, 877, 1723, 1911, 944, 1897, 778, 716, 1480, 1720, 1769, 315, 1971, 650, 870, 1698, 1347, 1583, 1066, 275, 699, 1418, 175, 342, 1959, 884, 1177, 179, 466, 246, 1760, 946, 153, 678, 1209, 3, 1495, 1908, 1817, 1695, 1313, 1191, 462, 479, 538, 1404, 1430, 1057, 1707, 1019, 895, 406, 164, 956, 647, 1564, 622, 843, 752, 1140, 523, 1241, 1294, 217, 1601, 1831, 1071, 1436, 1473, 190, 1062, 359, 1917, 1649, 17, 911, 1548, 1587, 1250, 531, 794, 1119, 1678, 1915, 262, 1205, 1337, 341, 580, 273, 249, 1682, 1521, 1857, 620, 1872, 1809, 836, 817, 247, 722, 1782, 719, 86, 1481, 1364, 1835, 701, 1261, 762, 429, 1044, 1994, 1486, 1651, 1969, 1484, 280, 1251, 1658, 366, 1546, 1739, 583, 698, 1942, 1216, 1690, 395, 113, 352, 1117, 230, 1655, 1408, 517, 1000, 1420, 422, 1985, 1257, 1238, 237, 881, 926, 343, 340, 544, 1557, 39, 148]\n",
            "Returned: (True, [601, 1240, 244, 1599, 655, 1307, 292, 186, 84, 798, 1482, 1392, 1370, 1759, 918, 7, 440, 66, 1228, 820, 1516, 1506, 139, 1489, 806, 1785, 1173, 62, 1662, 1391, 639, 289, 1316, 1526, 721, 1645, 553, 567, 1040, 675, 504, 1453, 853, 1352, 1451, 1083, 110, 1427, 748, 1367, 229, 1978, 1202, 201, 208, 910, 389, 1863, 138, 457, 1820, 1330, 1001, 1078, 64, 1568, 1160, 1163, 1894, 94, 1929, 219, 1711, 1087, 1728, 438, 707, 942, 651, 1974, 1622, 1792, 1264, 1593, 767, 281, 211, 1230, 43, 1357, 542, 1758, 1425, 203, 126, 574, 1500, 1943, 118, 1134, 1606, 231, 1493, 1517, 644, 1814, 1006, 1355, 325, 185, 916, 983, 586, 197, 632, 642, 189, 703, 1406, 1053, 561, 55, 1212, 261, 271, 609, 686, 934, 1955, 864, 592, 1091, 471, 702, 1644, 168, 1232, 1333, 1440, 1227, 1254, 955, 1637, 782, 1535, 174, 1183, 128, 1588, 1021, 73, 47, 1332, 755, 1842, 981, 1756, 1399, 306, 937, 952, 618, 1041, 673, 659, 368, 119, 948, 1603, 114, 1020, 1898, 527, 1110, 311, 1274, 564, 706, 688, 776, 810, 979, 1511, 1924, 1981, 1176, 856, 1199, 502, 1499, 1170, 635, 1618, 1616, 713, 693, 1300, 1858, 87, 1004, 1916, 1090, 196, 743, 304, 1968, 1565, 1409, 1024, 1382, 569, 431, 1679, 1667, 1691, 1876, 76, 1276, 288, 829, 397, 1928, 1445, 1709, 1233, 764, 1346, 1904, 1, 1248, 960, 681, 258, 931, 477, 809, 1545, 565, 1868, 97, 1740, 1412, 1921, 1433, 720, 754, 96, 80, 1747, 270, 1380, 1696, 470, 1456, 1467, 1704, 1991, 883, 940, 768, 1604, 824, 1137, 57, 821, 1379, 1735, 1284, 1471, 1852, 766, 1575, 775, 520, 984, 199, 1470, 990, 731, 626, 978, 2, 614, 1631, 161, 1267, 815, 1088, 409, 407, 454, 1159, 1847, 1918, 420, 297, 723, 294, 1902, 296, 1015, 160, 1217, 582, 973, 1947, 167, 660, 453, 299, 730, 1873, 1431, 560, 1029, 423, 1428, 1538, 1187, 1509, 21, 70, 1781, 1849, 1485, 1035, 1398, 1394, 146, 215, 967, 1275, 1988, 1361, 625, 1039, 1584, 907, 357, 428, 77, 1528, 627, 1345, 265, 1990, 875, 1520, 1576, 298, 9, 277, 1158, 757, 1393, 547, 1895, 1903, 85, 276, 1459, 1887, 1641, 1940, 424, 667, 1560, 932, 1547, 1802, 1434, 1686, 1650, 1429, 1744, 451, 640, 1551, 163, 487, 181, 307, 774, 780, 938, 1405, 1627, 239, 1725, 461, 1822, 1096, 1818, 257, 1893, 792, 379, 761, 1417, 1474, 1654, 328, 141, 1052, 478, 1181, 1670, 712, 1901, 1185, 629, 1642, 46, 1258, 145, 314, 814, 840, 1524, 1823, 1374, 1325, 1475, 122, 1097, 1003, 649, 1200, 1285, 595, 176, 1498, 1005, 391, 1362, 1794, 606, 102, 1515, 459, 291, 1438, 1710, 1055, 518, 1410, 899, 15, 1120, 846, 728, 1834, 1263, 831, 1685, 90, 1786, 427, 1614, 224, 1468, 634, 668, 852, 488, 677, 266, 1555, 985, 1824, 1869, 1478, 811, 753, 1598, 1967, 1570, 49, 1400, 832, 783, 1435, 1195, 1386, 381, 1143, 804, 1578, 1890, 1810, 879, 1505, 1591, 1125, 353, 1656, 933, 1961, 1750, 765, 1507, 1290, 807, 1207, 619, 823, 613, 480, 715, 225, 375, 539, 1156, 1996, 1790, 844, 1395, 1038, 1797, 1783, 593, 1889, 78, 51, 1080, 1179, 874, 808, 1793, 1304, 661, 947, 1826, 1883, 1537, 683, 1242, 1397, 1803, 1502, 1518, 1201, 854, 154, 744, 268, 1231, 346, 499, 269, 144, 1049, 1534, 641, 1180, 1951, 1387, 68, 1186, 530, 1311, 313, 796, 1128, 1594, 801, 1152, 194, 1457, 1260, 718, 182, 1138, 987, 1184, 1579, 274, 975, 1715, 891, 1776, 1278, 1269, 1016, 750, 1229, 1562, 72, 1882, 394, 1571, 1064, 1632, 484, 610, 1312, 1255, 1726, 98, 1681, 152, 489, 1871, 1780, 1853, 602, 408, 1956, 350, 1326, 1771, 29, 726, 1464, 1132, 1542, 902, 482, 1338, 1013, 1472, 1762, 666, 216, 370, 267, 386, 320, 805, 1075, 11, 1620, 1178, 383, 220, 360, 1302, 393, 1761, 1597, 1881, 1891, 1245, 452, 1210, 241, 1265, 559, 704, 1600, 550, 1949, 558, 248, 1321, 115, 1131, 631, 873, 1356, 503, 1683, 63, 392, 1058, 1608, 264, 83, 1832, 1610, 251, 1937, 316, 169, 58, 19, 508, 1581, 485, 736, 546, 830, 1706, 663, 354, 127, 1465, 1155, 1997, 443, 850, 26, 137, 575, 1025, 34, 1366, 507, 490, 1574, 170, 1558, 588, 412, 638, 1605, 1907, 448, 828, 1768, 1836, 134, 1462, 745, 1073, 598, 25, 1318, 95, 117, 1659, 724, 684, 1753, 458, 326, 1105, 74, 928, 319, 1741, 308, 1680, 61, 1806, 551, 351, 1845, 1837, 444, 848, 1854, 1350, 1114, 1856, 88, 1286, 223, 936, 1979, 1323, 1732, 1589, 1280, 1719, 1439, 1566, 380, 1193, 1444, 285, 1870, 436, 1376, 1171, 279, 1716, 286, 1072, 1309, 473, 173, 962, 909, 165, 1585, 1595, 930, 347, 1821, 1602, 1619, 300, 254, 150, 30, 236, 376, 578, 773, 1488, 0, 777, 48, 131, 646, 1147, 1948, 611, 1945, 1329, 228, 240, 465, 878, 917, 399, 958, 1225, 456, 441, 969, 1766, 922, 964, 1754, 860, 591, 491, 1162, 414, 1550, 23, 1107, 1982, 1795, 1463, 1266, 791, 345, 739, 1121, 1689, 1993, 1104, 1660, 1262, 1223, 1327, 1666, 1319, 1384, 1054, 1791, 579, 12, 125, 1874, 842, 1413, 1496, 1867, 714, 1023, 337, 1455, 1351, 1422, 1033, 665, 1688, 1504, 604, 317, 630, 109, 1426, 571, 1859, 348, 1133, 1919, 27, 903, 442, 205, 1888, 1077, 689, 965, 1243, 404, 302, 1122, 1226, 1247, 446, 888, 970, 905, 1424, 1303, 243, 664, 1194, 253, 1051, 1712, 177, 1182, 1674, 1703, 993, 1407, 1079, 1165, 633, 417, 838, 1115, 1784, 669, 362, 1118, 129, 679, 1042, 496, 1731, 1734, 1727, 1069, 1615, 1738, 1011, 1339, 1770, 540, 481, 1139, 1446, 494, 1414, 581, 1331, 1288, 421, 1093, 1423, 38, 426, 1733, 400, 1640, 1126, 402, 1841, 1494, 20, 1638, 890, 1559, 207, 1092, 1378, 425, 566, 1141, 837, 1102, 1964, 519, 607, 1772, 272, 13, 997, 1995, 549, 788, 1081, 309, 886, 636, 999, 365, 803, 1116, 991, 887, 492, 107, 556, 648, 1421, 645, 213, 781, 756, 1998, 332, 871, 1460, 467, 1839, 623, 1941, 373, 711, 1561, 65, 1237, 1531, 1512, 105, 1161, 1909, 1621, 1774, 1148, 511, 894, 1353, 868, 82, 855, 1416, 986, 155, 1014, 1501, 1611, 1124, 963, 89, 1992, 385, 212, 1801, 290, 103, 198, 1816, 327, 1671, 995, 1580, 1596, 847, 1101, 1553, 183, 813, 1466, 1913, 1063, 324, 851, 1569, 210, 256, 841, 1009, 1860, 1819, 227, 384, 318, 1342, 1612, 361, 162, 1415, 1617, 616, 411, 1623, 543, 410, 260, 1855, 483, 418, 1592, 996, 920, 941, 108, 857, 858, 1648, 548, 682, 1811, 1324, 992, 1065, 1668, 1146, 329, 976, 1724, 915, 1279, 147, 1939, 71, 524, 797, 972, 1987, 1925, 1554, 521, 1363, 1450, 193, 1865, 1008, 156, 1673, 44, 1573, 135, 142, 40, 1368, 1539, 430, 552, 1022, 1403, 1510, 1717, 512, 1957, 628, 1046, 897, 1866, 526, 1970, 323, 535, 1838, 10, 1910, 692, 949, 214, 746, 1256, 1751, 52, 1341, 557, 747, 1371, 338, 1544, 226, 235, 516, 834, 1900, 1214, 101, 1789, 892, 1829, 789, 1787, 1246, 445, 1962, 1692, 1532, 1757, 1007, 221, 464, 784, 1885, 1111, 833, 1779, 339, 1358, 1389, 1381, 1609, 1514, 116, 495, 819, 382, 906, 1935, 405, 696, 674, 1808, 876, 1665, 171, 880, 1150, 1830, 882, 534, 1402, 1848, 705, 396, 770, 700, 1476, 56, 100, 364, 374, 1094, 1283, 1175, 1775, 28, 468, 157, 1960, 1322, 35, 760, 1773, 1973, 1028, 1613, 1944, 1306, 1208, 845, 1745, 242, 901, 1142, 372, 680, 1934, 204, 1086, 1273, 1443, 1699, 1032, 608, 570, 1736, 1864, 1190, 1984, 924, 1213, 403, 790, 99, 1630, 872, 1931, 1983, 1112, 867, 1763, 151, 1906, 1359, 1383, 200, 1714, 287, 787, 310, 1556, 415, 729, 195, 1365, 1722, 919, 799, 1169, 184, 1282, 959, 358, 1503, 439, 862, 333, 900, 1281, 1676, 172, 1344, 1700, 1567, 121, 1705, 133, 717, 1335, 859, 1664, 1624, 1196, 994, 159, 124, 1224, 1663, 1721, 1390, 671, 1164, 690, 676, 37, 1586, 758, 67, 1840, 749, 1755, 1525, 599, 59, 740, 416, 1135, 652, 1533, 727, 1508, 33, 771, 500, 1635, 1843, 587, 1582, 939, 419, 1197, 1268, 1235, 966, 708, 1718, 1639, 525, 522, 510, 621, 295, 1295, 826, 1036, 1012, 50, 349, 1099, 1375, 79, 1952, 1694, 1297, 1813, 1188, 953, 1815, 1742, 506, 590, 935, 1252, 1454, 6, 1034, 1986, 1950, 1259, 1010, 654, 861, 1442, 330, 1629, 732, 1634, 1976, 1479, 60, 437, 1529, 355, 238, 1541, 1372, 532, 974, 123, 1349, 1914, 301, 312, 921, 1633, 1221, 1222, 1850, 282, 923, 112, 785, 554, 1153, 1167, 1625, 1026, 1060, 1799, 472, 1315, 751, 1291, 1234, 904, 8, 233, 1432, 1729, 908, 1452, 149, 786, 1677, 1684, 1626, 1946, 42, 1752, 1203, 1590, 497, 1292, 954, 1204, 24, 284, 1061, 344, 793, 1441, 501, 1270, 1154, 1932, 515, 1144, 1082, 321, 536, 1701, 1687, 1206, 388, 1037, 390, 1314, 255, 1765, 998, 1448, 5, 1458, 709, 178, 863, 293, 250, 1340, 1437, 1317, 1076, 1149, 528, 132, 334, 1513, 1880, 800, 1328, 1563, 1886, 1098, 657, 1100, 545, 759, 1697, 1702, 1861, 772, 741, 1805, 1334, 1636, 589, 662, 1669, 1980, 1965, 1419, 1833, 143, 603, 1106, 977, 1540, 1646, 218, 474, 1661, 432, 1954, 1048, 81, 1166, 322, 576, 1377, 568, 1800, 982, 1972, 1804, 45, 1447, 1113, 1045, 22, 1123, 597, 1189, 140, 1923, 643, 1056, 209, 1936, 1369, 192, 1927, 1922, 925, 1490, 263, 1043, 1737, 1846, 31, 1108, 1396, 734, 563, 600, 584, 435, 1999, 1851, 653, 1348, 769, 447, 130, 763, 697, 913, 670, 187, 53, 450, 1296, 1047, 509, 615, 305, 951, 1145, 234, 369, 1354, 1491, 14, 1933, 869, 943, 988, 1027, 401, 1523, 1449, 1129, 449, 1966, 1401, 1343, 1920, 1788, 1938, 1074, 1461, 1748, 656, 585, 1930, 433, 1767, 1211, 1157, 1373, 694, 562, 1151, 1812, 1828, 687, 188, 136, 1653, 303, 1536, 1827, 331, 91, 1360, 573, 1272, 32, 968, 191, 1647, 93, 1089, 1879, 1168, 816, 1483, 104, 1899, 455, 1031, 957, 961, 206, 356, 1469, 166, 120, 1530, 1844, 1172, 1018, 16, 1953, 232, 914, 818, 1127, 1798, 1958, 283, 1320, 1657, 839, 710, 460, 672, 1989, 1298, 898, 691, 572, 1577, 158, 617, 1070, 54, 1643, 1130, 1713, 1017, 612, 1877, 1878, 1905, 1862, 779, 1301, 1607, 18, 912, 637, 1926, 1103, 1977, 1884, 1236, 893, 1497, 1289, 1136, 69, 825, 434, 927, 971, 827, 1743, 1239, 1308, 1109, 605, 594, 1218, 885, 980, 493, 180, 387, 202, 1095, 1249, 1572, 1778, 335, 555, 259, 1963, 413, 106, 1549, 1675, 733, 41, 75, 1067, 537, 685, 929, 4, 889, 377, 1305, 1219, 367, 1198, 737, 1892, 812, 92, 1293, 1271, 1030, 725, 1519, 1652, 398, 1215, 1277, 486, 505, 1875, 1764, 1477, 1244, 1693, 1896, 658, 866, 624, 742, 1310, 1068, 245, 541, 596, 1825, 822, 1002, 865, 1411, 950, 1730, 1796, 577, 278, 1253, 735, 1527, 1174, 1543, 849, 1299, 835, 36, 476, 475, 1708, 252, 795, 363, 371, 1807, 738, 945, 529, 1487, 336, 469, 513, 1912, 1672, 1975, 1220, 463, 989, 111, 378, 1050, 1385, 222, 498, 1552, 514, 1084, 802, 1777, 1522, 896, 1388, 1287, 1059, 533, 695, 1749, 1192, 1336, 1492, 1628, 1085, 1746, 877, 1723, 1911, 944, 1897, 778, 716, 1480, 1720, 1769, 315, 1971, 650, 870, 1698, 1347, 1583, 1066, 275, 699, 1418, 175, 342, 1959, 884, 1177, 179, 466, 246, 1760, 946, 153, 678, 1209, 3, 1495, 1908, 1817, 1695, 1313, 1191, 462, 479, 538, 1404, 1430, 1057, 1707, 1019, 895, 406, 164, 956, 647, 1564, 622, 843, 752, 1140, 523, 1241, 1294, 217, 1601, 1831, 1071, 1436, 1473, 190, 1062, 359, 1917, 1649, 17, 911, 1548, 1587, 1250, 531, 794, 1119, 1678, 1915, 262, 1205, 1337, 341, 580, 273, 249, 1682, 1521, 1857, 620, 1872, 1809, 836, 817, 247, 722, 1782, 719, 86, 1481, 1364, 1835, 701, 1261, 762, 429, 1044, 1994, 1486, 1651, 1969, 1484, 280, 1251, 1658, 366, 1546, 1739, 583, 698, 1942, 1216, 1690, 395, 113, 352, 1117, 230, 1655, 1408, 517, 1000, 1420, 422, 1985, 1257, 1238, 237, 881, 926, 343, 340, 544, 1557, 39, 148])\n",
            "\n",
            "===== Large graphs (2000 nodes, non-isomorphic: G vs H) =====\n",
            "Files: large_G.txt  vs  large_H.txt\n",
            "False []\n",
            "Returned: (False, [])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 9 — Testing the Algorithms\n",
        "\n",
        "You can test with the sample graphs from the project statement.\n",
        "\n",
        "Example:\n",
        "\n",
        "### g1.txt\n",
        "4 4\n",
        "1\n",
        "0 2 3\n",
        "1 3\n",
        "1 2\n",
        "\n",
        "### g2.txt\n",
        "4 4\n",
        "2 3\n",
        "2\n",
        "0 1 3\n",
        "0 2\n",
        "\n",
        "All four algorithms should output:\n",
        "True [1, 2, 0, 3]\n",
        "\n",
        "(or another valid permutation)\n"
      ],
      "metadata": {
        "id": "bUyN-V0IU6VJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create g1.txt**"
      ],
      "metadata": {
        "id": "zgdxmjVmXj59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile g1.txt\n",
        "4 4\n",
        "1\n",
        "0 2 3\n",
        "1 3\n",
        "1 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty-m4QxuXgFl",
        "outputId": "0c123030-0bf0-4a42-a9b9-44a136bcf04a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting g1.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create g2.txt**"
      ],
      "metadata": {
        "id": "O0elQC6qXkUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile g2.txt\n",
        "4 4\n",
        "2 3\n",
        "2\n",
        "0 1 3\n",
        "0 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QD7oTgiXhPB",
        "outputId": "3244cfb2-35f7-43c1-ed79-ba0d3da1559d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting g2.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing the project functions**"
      ],
      "metadata": {
        "id": "x6oQ_AA2XxmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Brute force:\")\n",
        "brute_force(\"g1.txt\", \"g2.txt\")\n",
        "\n",
        "print(\"Backtracking:\")\n",
        "backtracking(\"g1.txt\", \"g2.txt\")\n",
        "\n",
        "print(\"Degree Backtracking:\")\n",
        "degree_backtracking(\"g1.txt\", \"g2.txt\")\n",
        "\n",
        "print(\"WL Backtracking:\")\n",
        "weisfeiler_leman_backtracking(\"g1.txt\", \"g2.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-thgejEBXyO-",
        "outputId": "381467c9-1ee5-4eb8-d2aa-d4951bf6e82f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brute force:\n",
            "True [1, 2, 0, 3]\n",
            "Backtracking:\n",
            "True [1, 2, 0, 3]\n",
            "Degree Backtracking:\n",
            "True [1, 2, 0, 3]\n",
            "WL Backtracking:\n",
            "True [1, 2, 0, 3]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, [1, 2, 0, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 9 — Experimental Tests and Performance Evaluation\n",
        "\n",
        "In this section, we test all four implemented algorithms on several graph pairs.\n",
        "\n",
        "Goals:\n",
        "\n",
        "- Verify **correctness** on both isomorphic and non-isomorphic graphs.\n",
        "- Illustrate how performance changes with graph size.\n",
        "- Demonstrate the practical advantage of **Degree Backtracking** and **Weisfeiler–Leman Backtracking**, as mentioned in the project remarks.\n",
        "\n",
        "We use three types of test pairs:\n",
        "\n",
        "1. **Path vs Star (8 nodes)** — same number of nodes and edges, but different structure → *non-isomorphic*.  \n",
        "2. **Cycle on 6 nodes** — same cycle, different node labellings → *isomorphic*.  \n",
        "3. **Random tree on 10 nodes** and a permuted copy → *isomorphic*, slightly larger, WL-friendly.\n"
      ],
      "metadata": {
        "id": "-voijmVse3Pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Section 9 - Helper function to test and time the algorithms\n",
        "# ============================================\n",
        "\n",
        "import time\n",
        "\n",
        "def test_all_algorithms(name: str, path1: str, path2: str):\n",
        "    \"\"\"\n",
        "    Run all four algorithms on the given pair (path1, path2),\n",
        "    print the result and execution time for each.\n",
        "    Intended for small/medium graphs (up to ~8 nodes).\n",
        "    \"\"\"\n",
        "    print(f\"\\n===== Test: {name} =====\")\n",
        "    print(f\"Files: {path1}  vs  {path2}\\n\")\n",
        "\n",
        "    # 1) Brute force\n",
        "    start = time.perf_counter()\n",
        "    res_bf = brute_force(path1, path2)\n",
        "    t_bf = time.perf_counter() - start\n",
        "    print(f\"Brute force time: {t_bf:.6f} s   -> {res_bf}\")\n",
        "\n",
        "    # 2) Backtracking\n",
        "    start = time.perf_counter()\n",
        "    res_bt = backtracking(path1, path2)\n",
        "    t_bt = time.perf_counter() - start\n",
        "    print(f\"Backtracking time: {t_bt:.6f} s  -> {res_bt}\")\n",
        "\n",
        "    # 3) Degree-based backtracking\n",
        "    start = time.perf_counter()\n",
        "    res_deg = degree_backtracking(path1, path2)\n",
        "    t_deg = time.perf_counter() - start\n",
        "    print(f\"Degree backtracking time: {t_deg:.6f} s  -> {res_deg}\")\n",
        "\n",
        "    # 4) Weisfeiler–Leman backtracking\n",
        "    start = time.perf_counter()\n",
        "    res_wl = weisfeiler_leman_backtracking(path1, path2)\n",
        "    t_wl = time.perf_counter() - start\n",
        "    print(f\"WL backtracking time: {t_wl:.6f} s  -> {res_wl}\")\n"
      ],
      "metadata": {
        "id": "-vEL-1HThbzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.1 — Creating the Test Graph Files\n",
        "\n",
        "We now create three graph pairs:\n",
        "\n",
        "1. `path8.txt` and `star8.txt` — both on 8 nodes, but structurally different → *not isomorphic*.  \n",
        "2. `cycle6_a.txt` and `cycle6_b.txt` — two different labelings of the same 6-cycle → *isomorphic*.  \n",
        "3. `tree10_a.txt` and `tree10_b.txt` — a random tree on 10 nodes and a permuted copy → *isomorphic*, used as a larger example.\n"
      ],
      "metadata": {
        "id": "EcAMcJZGhvlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile path8.txt\n",
        "8 7\n",
        "1\n",
        "0 2\n",
        "1 3\n",
        "2 4\n",
        "3 5\n",
        "4 6\n",
        "5 7\n",
        "6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2JbYEGOhxsD",
        "outputId": "fce07bd0-192a-4719-dfc8-0de89f43e6e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting path8.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile star8.txt\n",
        "8 7\n",
        "1 2 3 4 5 6 7\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPK3oK84h2Nj",
        "outputId": "c44dbda7-e381-4153-fe81-79bc149c439b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting star8.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cycle6_a.txt\n",
        "6 6\n",
        "1 5\n",
        "0 2\n",
        "1 3\n",
        "2 4\n",
        "3 5\n",
        "4 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WVT_yP7h4gG",
        "outputId": "7127969b-15b9-4b7e-80cc-1448bbcb64a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cycle6_a.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cycle6_b.txt\n",
        "6 6\n",
        "2 3\n",
        "4 5\n",
        "0 4\n",
        "0 5\n",
        "1 2\n",
        "1 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPeWaYuWh68L",
        "outputId": "b4ebe01b-bbb8-4a93-b000-7987ae137dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cycle6_b.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Section 9.1 - Generate random 10-node tree pair (isomorphic)\n",
        "# ============================================\n",
        "\n",
        "import random\n",
        "\n",
        "def generate_random_tree(n: int):\n",
        "    \"\"\"\n",
        "    Generate a random tree on n nodes using a Prüfer sequence.\n",
        "    Trees are guaranteed to be distinguished by 1-WL refinement.\n",
        "    \"\"\"\n",
        "    if n <= 1:\n",
        "        return [set() for _ in range(n)]\n",
        "\n",
        "    # Prüfer sequence of length n-2\n",
        "    prufer = [random.randint(0, n-1) for _ in range(n - 2)]\n",
        "    degree = [1] * n\n",
        "    for v in prufer:\n",
        "        degree[v] += 1\n",
        "\n",
        "    leaves = [i for i in range(n) if degree[i] == 1]\n",
        "    leaves.sort()\n",
        "\n",
        "    adj = [set() for _ in range(n)]\n",
        "\n",
        "    for v in prufer:\n",
        "        leaf = leaves[0]\n",
        "        leaves.pop(0)\n",
        "\n",
        "        adj[leaf].add(v)\n",
        "        adj[v].add(leaf)\n",
        "\n",
        "        degree[leaf] -= 1\n",
        "        degree[v] -= 1\n",
        "\n",
        "        if degree[v] == 1:\n",
        "            leaves.append(v)\n",
        "            leaves.sort()\n",
        "\n",
        "    # Connect the last two leaves\n",
        "    a, b = leaves\n",
        "    adj[a].add(b)\n",
        "    adj[b].add(a)\n",
        "\n",
        "    return adj\n",
        "\n",
        "def save_graph(adj, fname: str):\n",
        "    n = len(adj)\n",
        "    m = sum(len(adj[i]) for i in range(n)) // 2\n",
        "    with open(fname, \"w\") as f:\n",
        "        f.write(f\"{n} {m}\\n\")\n",
        "        for i in range(n):\n",
        "            f.write(\" \".join(str(x) for x in adj[i]) + \"\\n\")\n",
        "\n",
        "# Generate tree T\n",
        "T = generate_random_tree(10)\n",
        "\n",
        "# Create an isomorphic copy T' using a random permutation\n",
        "perm = list(range(10))\n",
        "random.shuffle(perm)\n",
        "\n",
        "Tp = [set() for _ in range(10)]\n",
        "for i in range(10):\n",
        "    for j in T[i]:\n",
        "        Tp[perm[i]].add(perm[j])\n",
        "\n",
        "# Save both trees\n",
        "save_graph(T, \"tree10_a.txt\")\n",
        "save_graph(Tp, \"tree10_b.txt\")\n",
        "\n",
        "print(\"Generated tree10_a.txt and tree10_b.txt (10-node tree, isomorphic).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGamPNSxh_AY",
        "outputId": "465cb7c6-a0b5-4226-d400-9208787a9caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated tree10_a.txt and tree10_b.txt (10-node tree, isomorphic).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.2 — Running All Algorithms on the Graph Pairs\n",
        "\n",
        "We now run:\n",
        "\n",
        "- `brute_force`\n",
        "- `backtracking`\n",
        "- `degree_backtracking`\n",
        "- `weisfeiler_leman_backtracking`\n",
        "\n",
        "on:\n",
        "\n",
        "1. `path8.txt` vs `star8.txt` — non-isomorphic.  \n",
        "2. `cycle6_a.txt` vs `cycle6_b.txt` — isomorphic.  \n",
        "3. `tree10_a.txt` vs `tree10_b.txt` — isomorphic, larger tree (we skip brute force here because 10! is very large).\n"
      ],
      "metadata": {
        "id": "ZRJEFZNJh_vS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Section 9.2 - Execute tests\n",
        "# ============================================\n",
        "\n",
        "# 1) Non-isomorphic: path vs star (8 nodes)\n",
        "test_all_algorithms(\"Path vs Star (8 nodes, non-isomorphic)\", \"path8.txt\", \"star8.txt\")\n",
        "\n",
        "# 2) Isomorphic: 6-cycle\n",
        "test_all_algorithms(\"Cycle (6 nodes, isomorphic)\", \"cycle6_a.txt\", \"cycle6_b.txt\")\n",
        "\n",
        "# 3) Isomorphic: 10-node tree (skip brute force)\n",
        "print(\"\\n===== Test: Tree (10 nodes, isomorphic) =====\")\n",
        "print(\"Files: tree10_a.txt  vs  tree10_b.txt\\n\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "res_bt = backtracking(\"tree10_a.txt\", \"tree10_b.txt\")\n",
        "t_bt = time.perf_counter() - start\n",
        "print(f\"Backtracking time: {t_bt:.6f} s -> {res_bt}\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "res_deg = degree_backtracking(\"tree10_a.txt\", \"tree10_b.txt\")\n",
        "t_deg = time.perf_counter() - start\n",
        "print(f\"Degree backtracking time: {t_deg:.6f} s -> {res_deg}\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "res_wl = weisfeiler_leman_backtracking(\"tree10_a.txt\", \"tree10_b.txt\")\n",
        "t_wl = time.perf_counter() - start\n",
        "print(f\"WL backtracking time: {t_wl:.6f} s -> {res_wl}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZNxgSaoiCDu",
        "outputId": "6acfc3a7-b3be-4b54-da33-545bca3da182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Test: Path vs Star (8 nodes, non-isomorphic) =====\n",
            "Files: path8.txt  vs  star8.txt\n",
            "\n",
            "False []\n",
            "Brute force time: 0.000950 s   -> (False, [])\n",
            "False []\n",
            "Backtracking time: 0.000135 s  -> (False, [])\n",
            "False []\n",
            "Degree backtracking time: 0.000186 s  -> (False, [])\n",
            "False []\n",
            "WL backtracking time: 0.000102 s  -> (False, [])\n",
            "\n",
            "===== Test: Cycle (6 nodes, isomorphic) =====\n",
            "Files: cycle6_a.txt  vs  cycle6_b.txt\n",
            "\n",
            "True [0, 2, 4, 1, 5, 3]\n",
            "Brute force time: 0.000262 s   -> (True, [0, 2, 4, 1, 5, 3])\n",
            "True [0, 2, 4, 1, 5, 3]\n",
            "Backtracking time: 0.000210 s  -> (True, [0, 2, 4, 1, 5, 3])\n",
            "True [0, 2, 4, 1, 5, 3]\n",
            "Degree backtracking time: 0.000158 s  -> (True, [0, 2, 4, 1, 5, 3])\n",
            "True [0, 2, 4, 1, 5, 3]\n",
            "WL backtracking time: 0.000461 s  -> (True, [0, 2, 4, 1, 5, 3])\n",
            "\n",
            "===== Test: Tree (10 nodes, isomorphic) =====\n",
            "Files: tree10_a.txt  vs  tree10_b.txt\n",
            "\n",
            "True [5, 3, 7, 2, 4, 8, 1, 0, 6, 9]\n",
            "Backtracking time: 0.001472 s -> (True, [5, 3, 7, 2, 4, 8, 1, 0, 6, 9])\n",
            "True [5, 3, 7, 2, 4, 8, 1, 0, 6, 9]\n",
            "Degree backtracking time: 0.000373 s -> (True, [5, 3, 7, 2, 4, 8, 1, 0, 6, 9])\n",
            "True [5, 3, 7, 2, 4, 8, 1, 0, 6, 9]\n",
            "WL backtracking time: 0.000789 s -> (True, [5, 3, 7, 2, 4, 8, 1, 0, 6, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.3 — Interpretation of Results\n",
        "\n",
        "From these experiments, we typically observe:\n",
        "\n",
        "- **Path vs Star (8 nodes):**\n",
        "  - All four algorithms correctly return `False, []`.\n",
        "  - This confirms they can detect that graphs with the same n and m but different structure are not isomorphic.\n",
        "\n",
        "- **6-cycle (6 nodes, two labelings):**\n",
        "  - All four algorithms correctly return `True` with a valid permutation.\n",
        "  - Brute force is still fast here, but more advanced methods already start to show similar or better performance.\n",
        "\n",
        "- **Tree (10 nodes, isomorphic):**\n",
        "  - We skip brute force due to factorial complexity.\n",
        "  - Backtracking and Degree Backtracking succeed.\n",
        "  - **Weisfeiler–Leman Backtracking** is efficient and benefits from the tree structure, illustrating the power of structural refinement and message passing, as highlighted in the project remarks.\n",
        "\n",
        "Overall, these tests demonstrate:\n",
        "\n",
        "- **Correctness** of all four implementations on both isomorphic and non-isomorphic examples.\n",
        "- **Performance improvements** from:\n",
        "  - plain Backtracking → Degree Backtracking → Weisfeiler–Leman Backtracking.\n",
        "- A clear motivation for using partition refinement and Weisfeiler–Leman ideas in practice.\n",
        "\n",
        "This completes the experimental validation of the project.\n"
      ],
      "metadata": {
        "id": "T6253fPOiD_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 9.4 — Discussion and Context of previous sections\n",
        "\n",
        "**Remark 3 — Real-life application.**  \n",
        "The (sub)graph isomorphism problem appears in many practical settings.  \n",
        "One concrete example is image geolocalization, where a query image is matched to a map\n",
        "by finding correspondences between visual features and landmarks represented as graphs.\n",
        "(See: *Approximate Subgraph Isomorphism for Image Localization*, Vaishaal Shankar et al., Electronic Imaging 2016.)\n",
        "\n",
        "**Remark 4 — Complexity.**  \n",
        "The graph isomorphism problem is in NP, but is not known to be in P and not known to be NP-complete,\n",
        "so it is believed to be NP-intermediate.  \n",
        "In contrast, the subgraph isomorphism problem is known to be NP-complete.\n",
        "\n",
        "**Remark 5 — Weisfeiler–Leman and message passing.**  \n",
        "The Weisfeiler–Leman refinement used in this project repeatedly updates node \"colors\"\n",
        "based on the multiset of colors of their neighbors.  \n",
        "This iterative \"message passing\" is conceptually similar to how modern Graph Neural Networks (GNNs)\n",
        "aggregate and propagate information over neighbors in each layer.\n"
      ],
      "metadata": {
        "id": "1NuuBolNcDxj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ============================================\n",
        "# Section 10 — Large Random Graph Performance Tests (≈2000 nodes)\n",
        "# ============================================\n",
        "\n",
        "In this section, we evaluate the *scalability* and *efficiency* of the algorithms on **very large graphs**.\n",
        "\n",
        "Full isomorphism search (backtracking, degree-backtracking, WL-backtracking) is **factorial in the worst case**,\n",
        "so graphs with *thousands* of nodes cannot be solved with mapping-based algorithms.\n",
        "\n",
        "However, the **Weisfeiler–Leman color refinement** (stable partition and stable double partition) is *fast*, running in approximately:\n",
        "\n",
        "\\[\n",
        "O(n \\log n + m)\n",
        "\\]\n",
        "\n",
        "and is widely used in large-scale graph tasks, including graph neural networks (Remark 5).\n",
        "\n",
        "### Goals of this section:\n",
        "\n",
        "1. Generate a very large random graph \\(G\\) with **n = 2000 nodes**.\n",
        "2. Create an *isomorphic* version \\(G_{\\text{perm}}\\) by randomly permuting node IDs.\n",
        "3. Generate another random graph \\(H\\) (same size and density) that is *unlikely isomorphic*.\n",
        "4. Run **fast invariants** and **stable double partition (1-WL refinement)** on:\n",
        "   - \\(G\\) vs \\(G_{\\text{perm}}\\)  → *should stay compatible*\n",
        "   - \\(G\\) vs \\(H\\) → *should quickly detect incompatibility*\n",
        "5. Measure the execution time of WL refinement on large graphs.\n",
        "\n",
        "This provides a realistic performance experiment demonstrating that the implementation scales to graphs far beyond the size where backtracking is feasible.\n"
      ],
      "metadata": {
        "id": "RS7B4aVo85I_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Section 10.1 - Large random graph generator\n",
        "# ============================================\n",
        "\n",
        "import random\n",
        "\n",
        "def generate_erdos_renyi_graph(n: int, avg_degree: int):\n",
        "    \"\"\"\n",
        "    Generate a random undirected graph G(n, p) with approximately the given\n",
        "    average degree using edge probability p = avg_degree / (n - 1).\n",
        "    Returns adjacency list as List[Set[int]].\n",
        "    \"\"\"\n",
        "    if n <= 0:\n",
        "        return []\n",
        "\n",
        "    p = avg_degree / max(1, n - 1)\n",
        "    adj = [set() for _ in range(n)]\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(i + 1, n):\n",
        "            if random.random() < p:\n",
        "                adj[i].add(j)\n",
        "                adj[j].add(i)\n",
        "\n",
        "    return adj\n",
        "\n",
        "\n",
        "def save_graph_adj(adj, fname: str):\n",
        "    \"\"\"\n",
        "    Save adjacency list to file in project format.\n",
        "    \"\"\"\n",
        "    n = len(adj)\n",
        "    m = sum(len(adj[i]) for i in range(n)) // 2\n",
        "    with open(fname, \"w\") as f:\n",
        "        f.write(f\"{n} {m}\\n\")\n",
        "        for i in range(n):\n",
        "            f.write(\" \".join(str(x) for x in adj[i]) + \"\\n\")\n"
      ],
      "metadata": {
        "id": "aXTban2P84Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_graph(adj, name=\"Graph\", preview=10):\n",
        "    \"\"\"\n",
        "    Print a readable summary of a large graph:\n",
        "    - number of nodes\n",
        "    - number of edges\n",
        "    - degree stats\n",
        "    - preview of adjacency list for the first N nodes\n",
        "    \"\"\"\n",
        "    n = len(adj)\n",
        "    m = sum(len(adj[i]) for i in range(n)) // 2\n",
        "    degrees = [len(adj[i]) for i in range(n)]\n",
        "\n",
        "    print(f\"\\n===== Summary of {name} =====\")\n",
        "    print(f\"Nodes: {n}\")\n",
        "    print(f\"Edges: {m}\")\n",
        "    print(f\"Min degree: {min(degrees)}\")\n",
        "    print(f\"Max degree: {max(degrees)}\")\n",
        "    print(f\"Average degree: {sum(degrees)/n:.2f}\")\n",
        "    print(f\"Degree distribution preview (first 10): {degrees[:10]}\")\n",
        "\n",
        "    print(f\"\\nFirst {preview} adjacency rows:\")\n",
        "    for i in range(min(preview, n)):\n",
        "        print(f\"{i}: {sorted(list(adj[i]))}\")"
      ],
      "metadata": {
        "id": "FMCOuJZTb5L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Section 10.2 - Create large random graphs (n = 2000)\n",
        "# ============================================\n",
        "\n",
        "n_large = 2000\n",
        "avg_degree = 20   # change this if you want more/less dense graphs\n",
        "\n",
        "print(\"Generating large random graphs...\")\n",
        "\n",
        "# 1) G: Random graph\n",
        "G_large = generate_erdos_renyi_graph(n_large, avg_degree)\n",
        "\n",
        "# 2) G_perm: Random permutation of G (isomorphic)\n",
        "perm = list(range(n_large))\n",
        "random.shuffle(perm)\n",
        "\n",
        "G_perm = [set() for _ in range(n_large)]\n",
        "for i in range(n_large):\n",
        "    for j in G_large[i]:\n",
        "        G_perm[perm[i]].add(perm[j])\n",
        "\n",
        "# 3) H: Independent random graph\n",
        "H_large = generate_erdos_renyi_graph(n_large, avg_degree)\n",
        "\n",
        "# Save them\n",
        "save_graph_adj(G_large, \"large_G.txt\")\n",
        "save_graph_adj(G_perm, \"large_G_perm.txt\")\n",
        "save_graph_adj(H_large, \"large_H.txt\")\n",
        "\n",
        "print(\"✔ Saved large_G.txt, large_G_perm.txt (isomorphic), large_H.txt (random).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB0NMEQY96Sp",
        "outputId": "f7986287-84a6-4208-abe5-faf133a69f7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating large random graphs...\n",
            "✔ Saved large_G.txt, large_G_perm.txt (isomorphic), large_H.txt (random).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G_large_loaded  = load_graph(\"large_G.txt\")\n",
        "G_perm_loaded   = load_graph(\"large_G_perm.txt\")\n",
        "H_large_loaded  = load_graph(\"large_H.txt\")"
      ],
      "metadata": {
        "id": "GWTnteuddGgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_graph(G_large_loaded, \"Large Graph G\")\n",
        "summarize_graph(G_perm_loaded, \"Large Graph G_perm\")\n",
        "summarize_graph(H_large_loaded, \"Large Graph H\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftlngJU0b-24",
        "outputId": "61656cf4-7df4-4c15-d6b6-74acd448e204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Summary of Large Graph G =====\n",
            "Nodes: 2000\n",
            "Edges: 20111\n",
            "Min degree: 8\n",
            "Max degree: 33\n",
            "Average degree: 20.11\n",
            "Degree distribution preview (first 10): [23, 13, 18, 10, 20, 25, 21, 27, 30, 22]\n",
            "\n",
            "First 10 adjacency rows:\n",
            "0: [18, 283, 297, 493, 515, 600, 816, 827, 859, 1246, 1267, 1318, 1337, 1434, 1461, 1497, 1523, 1573, 1636, 1855, 1934, 1971, 1989]\n",
            "1: [30, 67, 132, 499, 842, 1012, 1274, 1501, 1801, 1876, 1897, 1907, 1970]\n",
            "2: [72, 456, 657, 680, 682, 801, 829, 860, 904, 941, 1100, 1215, 1224, 1235, 1269, 1788, 1857, 1962]\n",
            "3: [239, 615, 673, 1017, 1052, 1296, 1570, 1579, 1670, 1791]\n",
            "4: [31, 220, 294, 317, 466, 608, 610, 933, 995, 1006, 1241, 1269, 1361, 1435, 1465, 1527, 1799, 1839, 1843, 1958]\n",
            "5: [299, 352, 369, 448, 478, 530, 600, 778, 832, 888, 1012, 1045, 1081, 1103, 1104, 1344, 1453, 1482, 1542, 1620, 1665, 1801, 1805, 1892, 1975]\n",
            "6: [114, 277, 306, 372, 561, 651, 652, 733, 911, 1074, 1188, 1239, 1338, 1445, 1504, 1525, 1597, 1692, 1693, 1768, 1952]\n",
            "7: [165, 177, 262, 272, 292, 510, 597, 615, 851, 904, 941, 952, 1051, 1101, 1130, 1182, 1453, 1526, 1558, 1565, 1655, 1666, 1756, 1838, 1879, 1931, 1956]\n",
            "8: [14, 52, 55, 90, 120, 249, 262, 282, 331, 411, 460, 500, 587, 721, 806, 877, 881, 895, 1021, 1071, 1100, 1193, 1299, 1326, 1364, 1467, 1500, 1570, 1722, 1726]\n",
            "9: [15, 51, 250, 280, 329, 478, 624, 714, 736, 749, 803, 842, 1154, 1226, 1385, 1407, 1474, 1569, 1646, 1704, 1884, 1963]\n",
            "\n",
            "===== Summary of Large Graph G_perm =====\n",
            "Nodes: 2000\n",
            "Edges: 20111\n",
            "Min degree: 8\n",
            "Max degree: 33\n",
            "Average degree: 20.11\n",
            "Degree distribution preview (first 10): [24, 11, 28, 21, 26, 20, 16, 26, 14, 18]\n",
            "\n",
            "First 10 adjacency rows:\n",
            "0: [22, 144, 223, 225, 336, 596, 612, 630, 661, 741, 757, 914, 921, 1019, 1029, 1077, 1125, 1128, 1364, 1511, 1621, 1642, 1672, 1770]\n",
            "1: [167, 215, 341, 684, 772, 1036, 1227, 1233, 1510, 1722, 1976]\n",
            "2: [35, 43, 125, 192, 196, 228, 257, 364, 408, 419, 490, 588, 611, 651, 833, 998, 1179, 1232, 1357, 1435, 1530, 1586, 1708, 1760, 1807, 1817, 1837, 1946]\n",
            "3: [8, 117, 185, 189, 269, 342, 361, 413, 427, 801, 879, 905, 917, 1250, 1285, 1313, 1353, 1528, 1729, 1760, 1936]\n",
            "4: [10, 264, 271, 303, 342, 345, 404, 429, 439, 541, 571, 628, 632, 671, 688, 706, 720, 861, 1117, 1179, 1453, 1533, 1550, 1584, 1732, 1862]\n",
            "5: [118, 313, 387, 402, 417, 568, 605, 625, 718, 808, 833, 1050, 1106, 1157, 1429, 1648, 1747, 1918, 1935, 1996]\n",
            "6: [101, 121, 596, 755, 902, 981, 1138, 1140, 1347, 1362, 1460, 1496, 1509, 1588, 1644, 1658]\n",
            "7: [102, 345, 421, 447, 460, 512, 563, 599, 637, 671, 735, 814, 905, 1119, 1141, 1335, 1341, 1362, 1421, 1472, 1490, 1500, 1513, 1618, 1654, 1809]\n",
            "8: [3, 152, 205, 210, 263, 309, 352, 440, 971, 1017, 1040, 1131, 1145, 1907]\n",
            "9: [163, 259, 373, 442, 502, 525, 731, 906, 911, 944, 1078, 1148, 1338, 1424, 1529, 1540, 1710, 1737]\n",
            "\n",
            "===== Summary of Large Graph H =====\n",
            "Nodes: 2000\n",
            "Edges: 19987\n",
            "Min degree: 6\n",
            "Max degree: 37\n",
            "Average degree: 19.99\n",
            "Degree distribution preview (first 10): [20, 20, 14, 16, 19, 19, 17, 14, 28, 18]\n",
            "\n",
            "First 10 adjacency rows:\n",
            "0: [98, 100, 213, 215, 317, 364, 448, 706, 726, 730, 795, 878, 908, 1315, 1433, 1515, 1521, 1599, 1816, 1840]\n",
            "1: [22, 41, 63, 138, 290, 327, 617, 733, 761, 999, 1062, 1316, 1527, 1539, 1611, 1646, 1789, 1959, 1964, 1978]\n",
            "2: [74, 85, 352, 547, 609, 733, 983, 1261, 1388, 1521, 1543, 1607, 1809, 1850]\n",
            "3: [108, 213, 662, 794, 819, 871, 886, 1155, 1364, 1503, 1588, 1632, 1793, 1946, 1949, 1987]\n",
            "4: [59, 229, 255, 304, 371, 500, 507, 593, 687, 981, 1100, 1187, 1462, 1581, 1602, 1611, 1743, 1829, 1917]\n",
            "5: [95, 233, 444, 459, 585, 590, 638, 667, 879, 1013, 1071, 1182, 1280, 1292, 1320, 1520, 1675, 1805, 1916]\n",
            "6: [500, 573, 582, 657, 704, 833, 1016, 1033, 1224, 1282, 1383, 1559, 1619, 1699, 1897, 1959, 1986]\n",
            "7: [102, 115, 150, 227, 381, 443, 891, 1073, 1430, 1442, 1537, 1588, 1806, 1895]\n",
            "8: [149, 211, 220, 292, 352, 361, 440, 598, 784, 865, 918, 948, 1219, 1233, 1237, 1401, 1424, 1514, 1524, 1595, 1722, 1809, 1814, 1856, 1881, 1907, 1911, 1973]\n",
            "9: [114, 169, 256, 264, 281, 337, 349, 620, 648, 677, 757, 1095, 1395, 1654, 1725, 1825, 1848, 1987]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # ============================================\n",
        "# Section 10.3 - Time WL refinement on large graphs\n",
        "# ============================================\n",
        "\n",
        "import time\n",
        "\n",
        "def time_wl_refinement(name, adjA, adjB):\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "\n",
        "    # Quick invariants (degree multisets)\n",
        "    inv_ok = quick_invariants_match(adjA, adjB)\n",
        "    print(f\"Degree multiset match: {inv_ok}\")\n",
        "\n",
        "    if not inv_ok:\n",
        "        print(\"Rejected by degree-invariants.\")\n",
        "        return\n",
        "\n",
        "    # Build degree partitions\n",
        "    ntpA, pA = _build_degree_partition(adjA)\n",
        "    ntpB, pB = _build_degree_partition(adjB)\n",
        "\n",
        "    start = time.perf_counter()\n",
        "    result = stable_double_partition(adjA, ntpA, pA, adjB, ntpB, pB)\n",
        "    elapsed = time.perf_counter() - start\n",
        "\n",
        "    if result is False:\n",
        "        print(\"WL refinement result: Incompatible (non-isomorphic).\")\n",
        "    else:\n",
        "        print(\"WL refinement result: Compatible (isomorphic candidate).\")\n",
        "\n",
        "    print(f\"Time: {elapsed:.4f} seconds\")\n",
        "\n",
        "\n",
        "# Load the graphs\n",
        "G_large_loaded  = load_graph(\"large_G.txt\")\n",
        "G_perm_loaded   = load_graph(\"large_G_perm.txt\")\n",
        "H_large_loaded  = load_graph(\"large_H.txt\")\n",
        "\n",
        "# Run WL refinement tests\n",
        "time_wl_refinement(\"G vs G_perm (isomorphic)\", G_large_loaded, G_perm_loaded)\n",
        "time_wl_refinement(\"G vs H (non-isomorphic)\", G_large_loaded, H_large_loaded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UbnE1aW99Hq",
        "outputId": "d4546236-9858-48ea-9051-75a7ce1f5744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- G vs G_perm (isomorphic) ---\n",
            "Degree multiset match: True\n",
            "WL refinement result: Compatible (isomorphic candidate).\n",
            "Time: 0.1345 seconds\n",
            "\n",
            "--- G vs H (non-isomorphic) ---\n",
            "Degree multiset match: False\n",
            "Rejected by degree-invariants.\n"
          ]
        }
      ]
    }
  ]
}